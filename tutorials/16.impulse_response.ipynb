{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SDialog dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setup the environment depending on weather we are running in Google Colab or Jupyter Notebook\n",
    "import os\n",
    "from IPython import get_ipython\n",
    "\n",
    "if \"google.colab\" in str(get_ipython()):\n",
    "    print(\"Running on CoLab\")\n",
    "\n",
    "    # Installing sdialog\n",
    "    !git clone https://github.com/qanastek/sdialog.git\n",
    "    %cd sdialog\n",
    "    %pip install -e .\n",
    "    %cd ..\n",
    "else:\n",
    "    print(\"Running in Jupyter Notebook\")\n",
    "    # Little hack to avoid the \"OSError: Background processes not supported.\" error in Jupyter notebooks\"\n",
    "    get_ipython().system = os.system"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Local installation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create a `.venv` using the root `requirement.txt` file and Python `3.11.14`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sdialog import Dialog\n",
    "from IPython.display import display"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load an existing dialogue"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In order to run the next steps in a fast manner, we will start from an existing dialog generated using previous tutorials:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path_dialog = \"../tests/data/demo_dialog_doctor_patient.json\"\n",
    "\n",
    "if not os.path.exists(path_dialog) and not os.path.exists(\"./demo_dialog_doctor_patient.json\"):\n",
    "    !wget https://raw.githubusercontent.com/qanastek/sdialog/refs/heads/main/tests/data/demo_dialog_doctor_patient.json\n",
    "    path_dialog = \"./demo_dialog_doctor_patient.json\"\n",
    "\n",
    "original_dialog = Dialog.from_file(path_dialog)\n",
    "original_dialog.print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tutorial 17: Impulse response and recording devices simulation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The key objective of this tutorial is to apply different microphone impulse responses to the audio obtains after the accoustics simulation of the room, allowing you to hear how the dialogue would sound as if recorded on various real-world devices."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sdialog.audio.dialog import AudioDialog\n",
    "from sdialog.audio.pipeline import AudioPipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Convert the original dialog into a audio enhanced dialog"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dialog: AudioDialog = AudioDialog.from_dialog(original_dialog)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load dSCAPER:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import scaper\n",
    "DATA_PATH = \"./dscaper_data_impulse_response\"\n",
    "os.makedirs(DATA_PATH, exist_ok=True)\n",
    "dsc = scaper.Dscaper(dscaper_base_path=DATA_PATH)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load the database of impulse reponses files available on our HuggingFace. You can also here create you own local database of IR files by using `LocalImpulseResponseDatabase`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sdialog.audio.impulse_response_database import HuggingFaceImpulseResponseDatabase\n",
    "impulse_response_database = HuggingFaceImpulseResponseDatabase(\"sdialog/impulse-responses\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we usually done in the previous tutorials, we are instantiating an `AudioPipeline` with `dscaper` since we are running all 3 steps of the pipeline, while also adding the new parameter `impulse_response_database` for the microphone simulation:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.makedirs(\"./audio_outputs_impulse_response\", exist_ok=True)\n",
    "audio_pipeline = AudioPipeline(\n",
    "    dir_audio=\"./audio_outputs_impulse_response\",\n",
    "    dscaper=dsc,\n",
    "    impulse_response_database=impulse_response_database\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "audio_pipeline.populate_dscaper([\"sdialog/background\",\"sdialog/foreground\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's generate a simple examination room:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sdialog.audio.room import DirectivityType\n",
    "from sdialog.audio.utils import SourceVolume, SourceType\n",
    "from sdialog.audio.jsalt import MedicalRoomGenerator, RoomRole"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "room = MedicalRoomGenerator().generate(args={\"room_type\": RoomRole.EXAMINATION})\n",
    "img = room.to_image()\n",
    "display(img)\n",
    "img.save(\"room.png\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And place speakers around the desk:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sdialog.audio.room import SpeakerSide, Role, RoomPosition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "room.place_speaker_around_furniture(speaker_name=Role.SPEAKER_1, furniture_name=\"desk\", max_distance=1.0, side=SpeakerSide.FRONT)\n",
    "room.place_speaker_around_furniture(speaker_name=Role.SPEAKER_2, furniture_name=\"desk\", max_distance=1.0, side=SpeakerSide.BACK)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can visualize the new positions of the speakers:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img = room.to_image()\n",
    "display(img)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And finally, we are generating the audios with room accoustics and the impulse response from a `SHURE_SM57` microphone:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sdialog.audio.processing import RecordingDevice"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dialog: AudioDialog = audio_pipeline.inference(\n",
    "    dialog,\n",
    "    environment={\n",
    "        \"room\": room,\n",
    "        \"background_effect\": \"white_noise\",\n",
    "        \"foreground_effect\": \"ac_noise_minimal\",\n",
    "        \"foreround_effect_position\": RoomPosition.TOP_RIGHT,\n",
    "        \"source_volumes\": {\n",
    "            SourceType.ROOM: SourceVolume.HIGH,\n",
    "            SourceType.BACKGROUND: SourceVolume.VERY_LOW\n",
    "        },\n",
    "        \"kwargs_pyroom\": {\n",
    "            \"ray_tracing\": True,\n",
    "            \"air_absorption\": True\n",
    "        }\n",
    "    },\n",
    "    do_step_1=True,\n",
    "    do_step_2=True,\n",
    "    do_step_3=True,\n",
    "    dialog_dir_name=\"demo_impulse_response\",\n",
    "    room_name=\"my_room_demo_shure\",\n",
    "    re_sampling_rate=16000,\n",
    "    recording_devices=[RecordingDevice.SHURE_SM57]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The recording devices are simulated after the 3rd step and re-sampling on the `room_name` you specified. All audios are saved within the step 3 metadata as paths (`audio_paths_post_processing`) pointing directly to them:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dialog.display()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### You can also perform microphone simulation by using the `to_audio` function from the `Dialog` class:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The first snippet are generating audios for the same room, with the same settings, but using two differents microphones configurations: `SENNHEISER_E906` and `SHURE_SM57`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_audio_dialog = original_dialog.to_audio(\n",
    "    do_step_1=True,\n",
    "    do_step_2=True,\n",
    "    do_step_3=True,\n",
    "    dir_audio=\"./audio_outputs_impulse_response\",\n",
    "    dialog_dir_name=\"demo_impulse_response_to_audio\",\n",
    "    room_name=\"my_room_demo_shure_to_audio_3\",\n",
    "    recording_devices=[RecordingDevice.SENNHEISER_E906, RecordingDevice.SHURE_SM57]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This second snippet is generating another room, with only one microphone (`SHURE_SM57`):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_audio_dialog = original_dialog.to_audio(\n",
    "    do_step_1=True,\n",
    "    do_step_2=True,\n",
    "    do_step_3=True,\n",
    "    dir_audio=\"./audio_outputs_impulse_response\",\n",
    "    dialog_dir_name=\"demo_impulse_response_to_audio\",\n",
    "    room_name=\"my_room_demo_shure_to_audio_4\",\n",
    "    recording_devices=[RecordingDevice.SHURE_SM57]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_audio_dialog.display()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Local impulse response database"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Impulse response database can be loaded from remote HF storage or locally. To do so, you need to give a `metadata_file` (at CSV / TSV / JSON format) which contains all information about the data and where they are stored. The required columns are `identifier,file_name,cab,speaker,microphone`.\n",
    "\n",
    "The paths need to be relative to `directory`, like so `./audio/my_ir.wav`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sdialog.audio.impulse_response_database import LocalImpulseResponseDatabase"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can start by downloading and extracting the archive that contains one example of impulse response like so:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "# If directory my_custom_voices is not present, download it\n",
    "if os.path.exists(\"my_custom_ir\"):\n",
    "    print(\"my_custom_ir already exists\")\n",
    "else:\n",
    "    !wget https://raw.githubusercontent.com/qanastek/sdialog/refs/heads/main/tests/data/my_custom_ir.zip -d my_custom_ir\n",
    "    !unzip my_custom_ir.zip\n",
    "    !rm my_custom_ir.zip"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Once done, you can use `LocalImpulseResponseDatabase` to load those data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "local_ir_database = LocalImpulseResponseDatabase(\n",
    "    metadata_file=\"/Users/yanislabrak/Downloads/impulse-responses/metadata.json\",  # Can be a json, csv, tsv file\n",
    "    directory=\"/Users/yanislabrak/Downloads/impulse-responses\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Number of impulse responses in the database:\", len(local_ir_database.get_data()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_local_audio_dialog = original_dialog.to_audio(\n",
    "    do_step_1=True,\n",
    "    do_step_2=True,\n",
    "    do_step_3=True,\n",
    "    dir_audio=\"./audio_outputs_impulse_response\",\n",
    "    dialog_dir_name=\"demo_impulse_response_to_audio\",\n",
    "    room_name=\"my_room_demo_shure_to_audio_5\",\n",
    "    impulse_response_database=local_ir_database,\n",
    "    recording_devices=[RecordingDevice.SHURE_SM57]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_local_audio_dialog.display()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
