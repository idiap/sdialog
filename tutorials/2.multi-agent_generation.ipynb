{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Synthetic Dialogue Generation with Multiple Agents"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Before we begin, let's first set up our environment..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setup the environment depending on weather we are running in Google Colab or Jupyter Notebook\n",
    "from IPython import get_ipython\n",
    "\n",
    "if \"google.colab\" in str(get_ipython()):\n",
    "    print(\"Running on CoLab\")\n",
    "    # Downloading only the \"output\" directory from the repository\n",
    "    !git init .\n",
    "    !git remote add -f origin https://github.com/Play-Your-Part/tutorials.git\n",
    "    !git config core.sparseCheckout true\n",
    "    !echo \"output\" >> .git/info/sparse-checkout\n",
    "    !git pull origin main\n",
    "\n",
    "    # Installing Ollama\n",
    "    !curl -fsSL https://ollama.com/install.sh | sh\n",
    "    # Installing sdialog\n",
    "    !git clone https://github.com/idiap/sdialog.git\n",
    "    %cd sdialog\n",
    "    %pip install -e .\n",
    "    %cd ..\n",
    "\n",
    "else:\n",
    "    print(\"Running in Jupyter Notebook\")\n",
    "    # Little hack to avoid the \"OSError: Background processes not supported.\" error in Jupyter notebooks\"\n",
    "    import os\n",
    "    get_ipython().system = os.system"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> ⚠️ If you're using **Colab**, please, **restart the runtime** once everything above is installed"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And let's first make sure we have the Ollama server running..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's start the ollama server\n",
    "!OLLAMA_KEEP_ALIVE=-1 ollama serve > /dev/null 2>&1 &\n",
    "!sleep 10  # Wait a bit for the server to start"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's use the default model (gemma3:27b), in case you want to replace the default one, you can use `sdialog.config` as follows:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sdialog\n",
    "\n",
    "# UNCOMMENT THE MODEL YOU WANT TO USE (TO OVERRIDE THE DEFAULT ONE)\n",
    "\n",
    "# use any model from https://ollama.com/library)\n",
    "# sdialog.config.set_llm(\"qwen2.5:14b\")\n",
    "# sdialog.config.set_llm(\"qwen2.5:1.5b\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Role-Play Multi-Agent-based Dialogue Generation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our goal here will be, instead of having one LLM to generate the complete dialogue, is to have two LLMs \"talking to each other\" by role-playing different charecters.\n",
    "\n",
    "Each character will be fully defined by its persona, as we did in the previous tutorial."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Persona"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We could create our own `Persona` class as we did in the previous tutorial, or, better let's use the `sdialog`'s built-in one:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sdialog.personas import Persona"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For now, let's only create one persona, Bob:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bob_persona = Persona(\n",
    "        name=\"Bob\",\n",
    "        role=\"great dad\",\n",
    "        circumstances=\"Your daughter will talk to you\",\n",
    "        background=\"Computer Science PhD.\",\n",
    "        personality=\"an extremely happy person that likes to help people\",\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's move to the fun part which is actually creating the LLM agent that will play this role.\n",
    "\n",
    "Fortunatelly, we can simply use `sdialog`'s built-in `PersonaAgent` class to create an agent for our personas."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Agent\n",
    "\n",
    "In its simplest form, the `PersonaAgent` class only takes a `Persona` object and the LLM model name to use for it, and will create the LLM-based agent for us:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sdialog.personas import Agent\n",
    "\n",
    "bob = Agent(bob_persona)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's talk with Bob a little bit as if we were his daughter:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bob(\"Hi dad!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bob(\"I need your help with my birthday\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bob(\"I want it to be about Lord of The Rings, do you think is possible?\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "That's so cool! Bob is really playing his \"great dad\" role well :)\n",
    "\n",
    "But instead of us talking to him directly, why not to create another character to play his daughter? Let's do it!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "alice_persona = Persona(\n",
    "    name=\"Alice\",\n",
    "    role=\"lovely daughter\",\n",
    "    circumstances=\"Your birthday is getting closer and you are talking with your dad to organize the party.\"\n",
    "                  \"You want your party to be themed as Lord of The Rings.\"\n",
    ")\n",
    "\n",
    "alice = Agent(alice_persona)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we have the agents for both characters, let's make them talk to each other so that they generate a (synthetic) dialogue for us by doing so:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dialog = alice.talk_with(bob)\n",
    "dialog.print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's imagine that, for some reason, we want make Alice to always begin all the conversation saying the same (randomly picked) utterance.\n",
    "\n",
    "We can specify either the utterance or utterances that agents are allowed to say as their first utterance by using the `.set_first_utterances()` method as follows:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "alice.set_first_utterances([\"Hi dad!\", \"Hello Dad, how are you?\"])\n",
    "# alice.set_first_utterances(\"Hi dad!\")  # you can pass a single utterance too\n",
    "\n",
    "dialog = alice.talk_with(bob)\n",
    "dialog.print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see that, this time, Alice first asked \"how are you?\" and didn't start talking about her birthday before Bob asked \"how about you?\".\n",
    "\n",
    "In a similar way as with our `DialogGenerator`, we can use the seed number above to re-generate the same dialogue by replicating the exact same interactions between both agents, as follows:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "alice.talk_with(bob, seed=1230091940).print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's now have fun a little bit and change Bob's personality to make him no longer a \"great dad\"..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bob_persona.personality = \"you are really shy, do not like to talk to people or help anyone, not even your doughter\"\n",
    "\n",
    "bad_bob = Agent(bob_persona, name=\"Bad Bob\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "alice.talk_with(bad_bob).print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Cool, huh? Our agent was able to play his new \"not so great dad\" role very well :)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Use Case: Dialogue Generation for STAR Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Before we begin this section, make sure you have the STAR dataset downloaded in your system, inside the `datasets` folder:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's clone the STAR dataset repository\n",
    "!git clone https://github.com/RasaHQ/STAR.git datasets/STAR\n",
    "\n",
    "# Let's check that `dialogues` and `tasks` folders are inside `datasets/STAR`\n",
    "!ls datasets/STAR"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we did with the previous tutorial, let's begin by importing STAR from `sdialog` and pointing it to the right path:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sdialog.datasets import STAR\n",
    "\n",
    "STAR.set_path(\"datasets/STAR/\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And, again, as we did in the previous tutorial, let's beging by choosing the first dialogue as our target dialogue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "TARGET_DIALOG = 1\n",
    "\n",
    "original_dialog = STAR.get_dialog(TARGET_DIALOG)\n",
    "original_dialog.print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Which has the following scenario:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scenario = STAR.get_dialog_scenario(TARGET_DIALOG)\n",
    "scenario"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we did in the previous tutorial, the goal is to be able to generate multiple dialogues for a given `scenario`.\n",
    "\n",
    "Before, we only had to find a way to describe each `scenario` using natural language so that we can pass it to our `DialogGenerator`.\n",
    "\n",
    "Likewise, now we have to find a way to create the right system and user agents for each `scenario` which in turn only involves retuning the right system and user `Persona`s for a given `scenario`.\n",
    "\n",
    "Fortunately, we can use the built-in `STAR.get_user_persona_for_scenario(scenario)` and `STAR.get_system_persona_for_scenario(scenario)` methods to achieve this.\n",
    "\n",
    "For instance, let's get the user persona for the `scenario` above:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "user_persona = STAR.get_user_persona_for_scenario(scenario)\n",
    "print(user_persona)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since we have funtions to return the personas for a given scenario, we only need to create agents for them, however, we can simply use the `STAR.get_agents_for_scenario(scenario)` to do it for us:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "system, user = STAR.get_agents_for_scenario(scenario)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, let's wrap up these previous steps in a simple function that for a given dialogue ID, it will first get its scenario and then return the corresponding system and user agents:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_agents_from_dialogue(dialog_id):\n",
    "    scenario = STAR.get_dialog_scenario(dialog_id)\n",
    "    return STAR.get_agents_for_scenario(scenario)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So that, we can get the agents for any dialogue as simple as:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "system, user = get_agents_from_dialogue(TARGET_DIALOG)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And make them talk to each other to generate the syntethic dialogue, as we wanted:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "system.dialog_with(user).print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Curious about the actual prompt the agents are using? you can simply use the `.get_prompt()` method to take a look at it. For instance, let's see the user agent's one:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(user.prompt())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, let's see what a dialogue for a more complex scenario looks like for more challenging `scenario`.\n",
    "\n",
    "In fact, let's use the same dialogue 5100 we used in the previous tutorial which is multi-task and does not follow a happy path:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "STAR.get_dialog_scenario(5100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "system, user = get_agents_from_dialogue(5100)\n",
    "system.dialog_with(user).print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Saving our dialogues"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Before we finish, as we did in the previous tutorial, let's generate one synthetic dialog for each happy `\"doctor_followup\"` dialog in STAR and save it to disk for later use."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm.auto import tqdm\n",
    "\n",
    "PATH_OUTPUT = \"output/STAR/multi-agents\"\n",
    "path_txt = os.path.join(PATH_OUTPUT, \"txt\")\n",
    "path_json = os.path.join(PATH_OUTPUT, \"json\")\n",
    "os.makedirs(path_txt, exist_ok=True)\n",
    "os.makedirs(path_json, exist_ok=True)\n",
    "\n",
    "for dialog in tqdm(STAR.get_dialogs(task_name=\"doctor_followup\", happy=True, multitask=False), desc=\"Dialog generation\"):\n",
    "    if os.path.exists(os.path.join(path_txt, f\"{dialog.dialogId}.txt\")):\n",
    "        continue\n",
    "\n",
    "    system, user = STAR.get_agents_from_dialogue(dialog.dialogId, model_name=MODEL_NAME)\n",
    "\n",
    "    dialog = system.dialog_with(user, id=dialog.dialogId, seed=dialog.dialogId, keep_bar=False)\n",
    "    dialog.to_file(os.path.join(path_json, f\"{dialog.dialogId}.json\"))\n",
    "    dialog.to_file(os.path.join(path_txt, f\"{dialog.dialogId}.txt\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, let's check the files were generated:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%ls output/STAR/multi-agents/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise: Doctor-Patient Conversations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Can you replicate the previous tutorial's exercise but this time using the multi-agent approach?\n",
    "\n",
    "1. Define the personas as before\n",
    "2. Create the two agents and make them talk to each other!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: do your magic!"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
