{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SDialog dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# If dialog_demo.json is not present, download it\n",
    "!wget https://raw.githubusercontent.com/qanastek/sdialog/refs/heads/main/misc/audio/dialog_demo.json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Link the sdialog module to the local directory if not done yet\n",
    "!ln -s ../src/sdialog ./sdialog"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sdialog\n",
    "from sdialog import Dialog"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load dialog"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "original_dialog = Dialog.from_file(\"dialog_demo.json\")\n",
    "original_dialog.print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Audio Generation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Instanciate voices database"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sdialog.audio.voice_database import DummyKokoroVoiceDatabase\n",
    "dummy_voice_database = DummyKokoroVoiceDatabase()\n",
    "dummy_voice_database.get_voice(genre=\"male\", age=20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Instanciate TTS model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sdialog.audio.tts_engine import KokoroTTS\n",
    "tts_engine = KokoroTTS()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup stage: Audio Dialog and Audio Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sdialog.audio.audio_dialog import AudioDialog\n",
    "from sdialog.audio.audio_pipeline import AudioPipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Convert the original dialog into a audio enhanced dialog"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dialog: AudioDialog = AudioDialog.from_dialog(original_dialog)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Instanciate the audio pipeline in order to use `Kokoro` (`tts_engine`) as the TTS model and save the audios outputs of all the dialogs into the directory `./audio_outputs`.\n",
    "\n",
    "The voices are sampled from the `dummy_voice_database` based on the persona attributes `age` and `gender`, as assigned during the original textual dialog."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%script false --no-raise-error\n",
    "!git clone https://github.com/cyrta/dscaper.git\n",
    "%pip install -r ../../../requirements-dscaper.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import scaper\n",
    "DATA_PATH = \"./dscaper_data\" # Path where the sound events, utterances and timelines database will be saved\n",
    "os.makedirs(DATA_PATH, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dsc = scaper.Dscaper(dscaper_base_path=DATA_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.makedirs(\"./audio_outputs\", exist_ok=True)\n",
    "audio_pipeline = AudioPipeline(\n",
    "    voice_database=dummy_voice_database,\n",
    "    tts_pipeline=tts_engine,\n",
    "    dscaper=dsc,\n",
    "    dir_audio=\"./audio_outputs\",\n",
    ")\n",
    "# audio_pipeline = AudioPipeline() # Can also be used with default values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Populate the sound events database\n",
    "audio_pipeline.populate_dscaper([\"sdialog/background\",\"sdialog/foreground\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sdialog.audio.room_generator import RoomGenerator, RoomRole"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "room = RoomGenerator().generate(RoomRole.CONSULTATION, room_size=8.0)\n",
    "print(room)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Perform the inference of the audio pipeline on the previously converted dialog. In this case we will focus on generating the \"unprocessed\" audio, which consist of the agregation of all utterances from the dialog. Rather than using the dialog identifier as the name of the directory, we are using here a custom directory name `demo_dialog_kokoro` which will be saved at `./audio_outputs/demo_dialog_kokoro/`. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sdialog.audio.room import MicrophonePosition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dialog: AudioDialog = audio_pipeline.inference(\n",
    "    dialog,\n",
    "    room=room, # Need to provide a room object to trigger the 3rd step of the audio pipeline\n",
    "    microphone_position=MicrophonePosition.CEILING_CENTERED, # Default is MicrophonePosition.MONITOR\n",
    "    do_step_1=True,\n",
    "    do_step_2=True,\n",
    "    do_step_3=True,\n",
    "    dialog_dir_name=\"demo_dialog_room_accoustic\",\n",
    "    room_name=\"my_room_config_1\"\n",
    ")\n",
    "print(dialog.audio_step_1_filepath)\n",
    "print(dialog.audio_step_2_filepath)\n",
    "print(dialog.audio_step_3_filepaths)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "jsalt",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.23"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
