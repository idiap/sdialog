{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Synthetic Dialogue Generation with Orchestration\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Before we begin, let's first set up our environment..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setup the environment depending on weather we are running in Google Colab or Jupyter Notebook\n",
    "from IPython import get_ipython\n",
    "\n",
    "if \"google.colab\" in str(get_ipython()):\n",
    "    print(\"Running on CoLab\")\n",
    "    # Downloading only the \"output\" directory from the repository\n",
    "    !git init .\n",
    "    !git remote add -f origin https://github.com/Play-Your-Part/tutorials.git\n",
    "    !git config core.sparseCheckout true\n",
    "    !echo \"output\" >> .git/info/sparse-checkout\n",
    "    !git pull origin main\n",
    "\n",
    "    # Installing Ollama\n",
    "    !curl -fsSL https://ollama.com/install.sh | sh\n",
    "    # Installing sdialog\n",
    "    !git clone https://github.com/idiap/sdialog.git\n",
    "    %cd sdialog\n",
    "    %pip install -e .\n",
    "    %cd ..\n",
    "\n",
    "else:\n",
    "    print(\"Running in Jupyter Notebook\")\n",
    "    # Little hack to avoid the \"OSError: Background processes not supported.\" error in Jupyter notebooks\"\n",
    "    import os\n",
    "    get_ipython().system = os.system"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> âš ï¸ If you're using **Colab**, please, **restart the runtime** once everything above is installed"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's change the default sdialog model (\"gemma3:27b\") by a slightly smaller model we can run in Colab:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sdialog\n",
    "\n",
    "sdialog.config.set_llm(\"qwen2.5:14b\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And let's first make sure we have the Ollama server is running"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import List\n",
    "from sdialog import Turn\n",
    "\n",
    "\n",
    "# Let's start the ollama server\n",
    "!OLLAMA_KEEP_ALIVE=-1 ollama serve > /dev/null 2>&1 &\n",
    "!sleep 10  # Wait a bit for the server to start"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Multi-Agent-based Dialogue Generation with Orchestration"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Introduction\n",
    "\n",
    "Let's begin by creating the same Bob agent from the last tutorial:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sdialog.personas import Persona, Agent\n",
    "\n",
    "bob_persona = Persona(\n",
    "        name=\"Bob\",\n",
    "        role=\"great dad\",\n",
    "        circumstances=\"Your daughter will talk to you\",\n",
    "        personality=\"an extremely happy person that likes to help people\",\n",
    ")\n",
    "\n",
    "bob = Agent(bob_persona)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As, we did in our last tutorial, let's talk with Bob a little bit:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bob(\"Hi dad!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bob(\"Dad, my birthday is coming up and I've been thinking about having a Lord of the Rings themed party. What do you think?\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What if, at this point, we would like to give some instruction to Bob agent so that we could influence his original behavior (i.e. change his original trajectory)?\n",
    "\n",
    "In fact, in `sdialog` all agents have a built-in `.instruct()` method that we can use to instruct agent \"on the fly\".\n",
    "\n",
    "For instance, at this point of the conversation, let's notify Bob that hubbit-sized cupcakes are not allowed in his region so that when we propose to have them, Bob is aware of this fact:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bob.instruct(\"hobbit-sized cupcakes are prohibit in your region, better regular ones\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So that if we now continue the conversation proposing to have hubbit-sized cupcakes, Bob will try to convince us otherwise:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bob(\"Yay! We could have hobbit-sized cupcakes and maybe some quests around the house!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It worked! but of course it won't be practical for us to manually `instruct()` the agents while they talk."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Simple Orchestration"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Instead, it would be desirable to have a separated component that can take care of that, in fact, that is precisely what `sdialog` orchestrators are for!\n",
    "\n",
    "More precisely, orchestrators receive, at each turn in a conversation, the current dialogue and utterance and return (if any) the desired instruction.\n",
    "\n",
    "Technically, an orchestrator is any class that inherits from the built-in `BaseOrchestrator` in which the `instruct(dialog, utterance)` method is populated.\n",
    "\n",
    "For instance, let's create our own `AngryOrchestrator` which will instruct the agent to \"get angry\" if either the current turn contains a trigger word or the conversation is too long:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sdialog.orchestrators import BaseOrchestrator\n",
    "\n",
    "\n",
    "class AngryOrchestrator(BaseOrchestrator):\n",
    "    # the class constructor takes either or both trigger conditions: the word or the dialogue length\n",
    "    def __init__(self, trigger_word: str, trigger_length: int = None):\n",
    "        self.trigger_word = trigger_word\n",
    "        self.trigger_length = trigger_length\n",
    "\n",
    "    # We will instruct() the agent either if...\n",
    "    def instruct(self, dialog: List[Turn], utterance: str) -> str:\n",
    "        # the trigger word is in the current utterance or...\n",
    "        if self.trigger_word in utterance:\n",
    "            return f\"Get angry because you don't like when your dad calls you {self.trigger_word}\"\n",
    "\n",
    "        # If the current dialogue is longer than the trigger length\n",
    "        if self.trigger_length and len(dialog) >= self.trigger_length:\n",
    "            return (\"Get really angry because you think the conversation is too long! \"\n",
    "                    \"be unpolite, rude and direct, finish the conversation abruptly, you are offended.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we have our first orchestrator, we can actually instantiate it with \"sweet\" as the actual trigger word:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "angry_orchestrator = AngryOrchestrator(trigger_word=\"sweet\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we have our \"triggered-by-sweet\" orchestrator, let's create our Alice agent again so we can orchestrate her."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "alice_persona = Persona(\n",
    "    name=\"Alice\",\n",
    "    role=\"lovely daughter\",\n",
    "    circumstances=\"Your birthday is getting closer and you are talking with your dad to organize the party.\"\n",
    "                  \"You want your party to be themed as Lord of The Rings.\"\n",
    ")\n",
    "alice = Agent(alice_persona, can_finish=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Before doing that, let's have Alice to talk with Bob in her vanilla version, without orchestration so we can compare it after applying the orchestration:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "alice.dialog_with(bob, seed=2770339798).print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ok, so we are now ready to apply the orchestrator to Alice, but how do we do that? easy! we can simply use the `|` operator as follows: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "alice = alice | angry_orchestrator"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we have a new Alice, which is the composition of the original `alice` with our `angry_orchestrator`, we can make her talk with Bob again:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dialog = alice.dialog_with(bob, seed=2770339798)\n",
    "dialog.print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see now that even though the conversation is exactly the same as before, in the 7th turn is Alice is triggered by Bob calling her \"sweetheart\" in turn 6, cool, huh?\n",
    "\n",
    "> ðŸ’¡ This means that even though we begin with a original trajectory (fixed by `seed=2770339798`), at certain point, we can created a fork from it (a new trajectory) in a very controlled manner. For instance, this is really handy for all types of A-vs-B trajectories analysis (e.g. good vs bad in Mechanical Interpretability).\n",
    "\n",
    "In case we want to see what happend \"under the hood\", we can make the orchestration visible by simply setting `orchestration=True` in the `.print()` function as follows:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dialog.print(orchestration=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Just for fun, let's now update our orchestrator to also trigger by length:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "angry_orchestrator.trigger_length = 6"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And let's have Alice to talk with Bob once more:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dialog = alice.dialog_with(bob, seed=2770339798)\n",
    "dialog.print(orchestration=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This time we see one extra instruction at the end, triggered by the conversation length, cool, huh? :)\n",
    "\n",
    "In `sdialog` we can get a JSON representation of our agents simply by using the `json()` method:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "alice.json()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we can see all the details about our Alice agent, including the model behind it, the persona and also the list of orchestrators influencing her bahavior.\n",
    "In case we want to remove all orchestration from an agent, we can use the `.clear_orchestrators()` method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "alice.clear_orchestrators()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If we see the details agent, we can see `\"orchestrators\"` field is no longer available:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "alice.json()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Persistent Orchestration"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the previous section, we learned how to instruct our agent using an orchestrator object.\n",
    "\n",
    "However, the instructions given by the orchestrators were not persistent.\n",
    "\n",
    "Perhaps this was not obvious because it was not clear wheather the instructions given had to permanently change the behavior of the agent or not.\n",
    "\n",
    "To make it more evident, let's suppose we want the `AngryOrchestrator` to permanently change the \"state of mind\" of the agent to be angry, then we could re-define create the class again with the following instruction:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class AngryOrchestrator(BaseOrchestrator):\n",
    "    def __init__(self, trigger_word: str):\n",
    "        self.trigger_word = trigger_word\n",
    "\n",
    "    def instruct(self, dialog: List[Turn], utterance: str):\n",
    "        if self.trigger_word in utterance:\n",
    "            # NOTE: this new instruction implyes a permanent change in the agent behavior\n",
    "            return (f\"You don't like when your dad calls you '{self.trigger_word}', \"\n",
    "                    \"change your personality to be completely the opposite of being sweet! be rude and furious from now on\")\n",
    "\n",
    "# Let's create a new instance of the orchestrator using \"sweet\" as trigger word as before\n",
    "angry_orchestrator = AngryOrchestrator(trigger_word=\"sweet\")\n",
    "alice.clear_orchestrators()\n",
    "alice = alice | angry_orchestrator\n",
    "\n",
    "# and let's create a dialogue between (angry) alice and bob\n",
    "dialog = alice.dialog_with(bob, seed=2770339798)\n",
    "dialog.print(orchestration=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see that, besides Alice replying with a _\"Don't call me 'sweetheart'!\"_ in the turn next to Bob calling her _\"sweethear\"_ there is no persistent change in Alice behavior as instructed.\n",
    "\n",
    "In cases were we want instruction to permanently affect the Agent behavior, we can simply implement our class by inheriting from `sdialog`'s built-in `BasePersistentOrchestrator` (instead of `BaseOrchestrator`). Let's do it again with the exact same definition as we did above:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sdialog.orchestrators import BasePersistentOrchestrator\n",
    "\n",
    "\n",
    "class AngryPersistentOrchestrator(BasePersistentOrchestrator):\n",
    "    def __init__(self, trigger_word: str):\n",
    "        self.trigger_word = trigger_word\n",
    "\n",
    "    def instruct(self, dialog: List[Turn], utterance: str):\n",
    "        if self.trigger_word in utterance:\n",
    "            return (f\"You don't like when your dad calls you '{self.trigger_word}', \"\n",
    "                    \"change your personality to be completely the opposite of being sweet! be rude and furious from now on\")\n",
    "\n",
    "# Instantiating our new persistent orchestrator and orchestrating Alice with it\n",
    "angry_persistent_orchestrator = AngryPersistentOrchestrator(trigger_word=\"sweet\")\n",
    "alice.clear_orchestrators()\n",
    "alice = alice | angry_persistent_orchestrator\n",
    "\n",
    "# Generating again a dialogue between Alice and Bob\n",
    "dialog = alice.dialog_with(bob, seed=2770339798)\n",
    "alice.clear_orchestrators()\n",
    "dialog.print(orchestration=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can now see that Alice changed his behavior as originally intended through the whole conversation (we can see that the agent kept it even to the end _\"Amazing? More like tolerable if you do everything right...\"_).\n",
    "\n",
    "Note also the orchestration messages in yellow says `[instruct-persistent]` to indicate this instruction is meant to be persistent, unlike in the previous one."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Compositional Orchestration"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So far we have learned how to orchestrate agents with persistent and non-persistent instructions with a simple orchestration example, but what happend if we would need to more complex orchestration?\n",
    "\n",
    "Of course we could create a complex orchestrator class with all logic inside, or better, we can decompose the orchestration into a composition of multiple simpler orchestrators.\n",
    "\n",
    "For instance, let's suppose we need an orchestration that (1) will make the Alice to change her mine with a probability of 30% while at the same time (2) get angry as before when Bob call her \"sweet\" and (3) forcing Alice to talk for 15 to 20 conversational turns.\n",
    "\n",
    "To achieve this, we can make use of some of the `sdialog`'s built-in orchestrator classes to model each behavior independently first as follows:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sdialog.orchestrators import LengthOrchestrator, ChangeMindOrchestrator, SimpleReflexOrchestrator\n",
    "\n",
    "len_orchestrator = LengthOrchestrator(min=15, max=20)\n",
    "change_mind_orchestrator = ChangeMindOrchestrator(probability=0.3, reasons=[\"too boring\", \"you don't like it\"], max_times=1)\n",
    "angry_orchestrator = SimpleReflexOrchestrator(condition=lambda utt: \"sweet\" in utt.lower(),\n",
    "                                              instruction=\"Get angry because you don't like when your dad calls you sweet\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And now we can simply orchestrate Alice by the three orchestrators as follows:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "alice = alice | len_orchestrator | change_mind_orchestrator | angry_orchestrator"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's now generate a dialogue again between Alice and Bob:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dialog = alice.dialog_with(bob, seed=2770339798)\n",
    "dialog.print(orchestration=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see that we achieved the intended goal, alice changed her mind, got angry when Bob called her \"sweetheart\" and at the same time the length of the conversation is between 15 and 20 turns (18 turns), as shown below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(dialog)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "All built-in orchestrator classes in `sdialog` have a `persistent` argument that the user can use to specify if the returned instructions are persistent or not, by default this parameter is set to `False` (as we can see above by the orchestration only containing `[instruct]` items).\n",
    "\n",
    "For instance, if we were to re-implement the persistent example form the previous example using the built-in `SimpleReflexOrchestrator` class, we can simply use the same instruction and trigger word and setting the `persistent=True` when creating the object, as follows:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "angry_persistent_orchestrator = SimpleReflexOrchestrator(\n",
    "    condition=lambda utt: \"sweet\" in utt.lower(),\n",
    "    instruction=\"You don't like when your dad calls you 'sweet', \"\n",
    "                \"change your personality to be completely the opposite of being sweet! be rude and furious from now on\",\n",
    "    persistent=True  # <== the instruction is persistent!\n",
    ")\n",
    "\n",
    "alice.clear_orchestrators()\n",
    "alice = alice | angry_persistent_orchestrator\n",
    "\n",
    "dialog = alice.dialog_with(bob, seed=2770339798)\n",
    "dialog.print(orchestration=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Use Case: Dialogue Generation for STAR Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Before we begin this section, make sure you have the STAR dataset downloaded in your system, inside the `datasets` folder:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's clone the STAR dataset repository\n",
    "!git clone https://github.com/RasaHQ/STAR.git datasets/STAR\n",
    "\n",
    "# Let's check that `dialogues` and `tasks` folders are inside `datasets/STAR`\n",
    "!ls datasets/STAR"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we did with the previous tutorials, let's begin by importing STAR from `sdialog` and pointing it to the right path:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sdialog.datasets import STAR\n",
    "\n",
    "# Let's set our STAR dataset path\n",
    "STAR.set_path(\"datasets/STAR/\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the previous tutorial we defined a function `get_agents_from_dialogue()` that, given a STAR dialogue ID, it returned the system and the user agents matching the scenario of the dialogue.\n",
    "\n",
    "Now we need to do exactly the same thing but the agents have to be orchestrated, but how exactly should be orchestrated?\n",
    "\n",
    "Well, it turns out that STAR dialogues are actually orchestrated too! Let's see the details in the next sub-section."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Original Orchestration in the Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's get the dialogue with id `1` from STAR as we did in the previous tutorials:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "TARGET_DIALOG = 1\n",
    "\n",
    "original_dialog = STAR.get_dialog(TARGET_DIALOG)\n",
    "original_dialog.print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This seems just like a regular dialogue between the the user and system.\n",
    "\n",
    "However, when this dataset was constructed, the persons playing the system and user roles were instructed and orchestrated to do it.\n",
    "\n",
    "We can see the original orchestration behind this dialogue if we set `orchestration=True` in the `print()` function:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "original_dialog.print(orchestration=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see that the orchestration for the user and the system is different: the user is guided by concrete instructions (marked with `(UserGuide)`) through the conversation while the system request suggesting for next possible responses (`[request_suggestions]`) to then pick one among the suggested responses (`[pick_suggestion]`).\n",
    "\n",
    "As it is described in the [STAR paper](https://arxiv.org/pdf/2010.11853), this difference foster users to behave more freely and system to be as much deterministic as possible.\n",
    "\n",
    "In the original dialogue files, dialogues are saved as a list of events containing not only the utterances but also the instructions and actions performed by the user and system. \n",
    "For instance, we can open the JSON file of dialogue `1` located in [`datasets/STAR/dialogues/1.json`](datasets/STAR/dialogues/1.json) and get access to this list of events by checking the content of the `\"Events\"` field.\n",
    "\n",
    "If we want to get access to the list of events of any given dialogue in `sdialog`, we can simply use the `.events` attribute of our dialogue objects as follows:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "original_dialog.events"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This events are what `sdialog` is using under the hood to pretty print the orchestration as part of the dialogue when using `.print(orchestration=True)` and more importantly, when we add orchestrator objects to our agents, all the orchestration will be also saved as events (as in the original STAR dataset).\n",
    "\n",
    "Now that we understand how it works under the hood and how the original dialogues in STAR were actually orchestrated, let's create the orchestrator objects for our system and user agents to try to emulate the same behavior as in the original dataset.\n",
    "\n",
    "Let's first get the base agents by using the function we created in the previous tutorial:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "system, user = STAR.get_agents_from_dialogue(TARGET_DIALOG)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And then we will create the orchestrator objects for them. Let's begin with the orchestration of the system agent first."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### System Agent Orchestration"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To simulate the \"suggest and pick responses\" original orchestration, we can use the built-in `SimpleResponseOrchestrator` class that, given a list of possible responses, it will instruct the agent to pick responses from this list:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sdialog.orchestrators import SimpleResponseOrchestrator"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For instance, let's load the original responses used to guide the human system in the original dataset:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "responses = STAR.get_dialog_responses(TARGET_DIALOG)[0]\n",
    "responses"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see here that, in STAR, each response is associated to a certain action (see `action:response` mapping in the dict). This is due to the fact that, as we know, system behavior for each task is described by flowchart of actions.\n",
    "\n",
    "In its simplest version, `SimpleResponseOrchestrator` can receive just a list of response utterances (without actions) that the orchestrator will use to suggest possible responses to the agent. For instance, for the responses above, we can:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# just get the list of response utteraces (ignoring the action names)\n",
    "utterances = [response for response in responses.values()]\n",
    "\n",
    "# and let's instantiate our orchestrator with them\n",
    "response_orchestrator = SimpleResponseOrchestrator(utterances)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's now add the orchestration to our system agent and generate the dialogue:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "system = system | response_orchestrator\n",
    "\n",
    "system.talk_with(user, seed=3068607470).print(orchestration=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see from the orchestration messages that our `SimpleResponseOrchestrator` performs the following tasks:\n",
    "1. First, it makes the agent to internally generate the original next response as before (\"Lookahead response\").\n",
    "2. It then uses this response to get the top-k most similar responses from the original list.\n",
    "3. Instruct the agent to pick the next response from this top-k most similar list.\n",
    "\n",
    "The `SimpleResponseOrchestrator` also allows to pass not only the utterances, but also the actions and the flowchart graph which will then internally use to suggest the next response based on the next actions from the graph. For instance, let's get again, the responses for our target dialogue but also its corresponding graph:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "graphs, responses = STAR.get_dialog_graphs_and_responses(TARGET_DIALOG)\n",
    "\n",
    "responses = responses[0]\n",
    "graph = graphs[0]\n",
    "\n",
    "graph"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's now create again our orchestrator but this time passing also the graph:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "response_action_orchestrator = SimpleResponseOrchestrator(responses, graph=graph)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's replace the previous orchestrator by the new one and generate the dialogue again:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "system.clear_orchestrators()\n",
    "system = system | response_action_orchestrator\n",
    "\n",
    "system.talk_with(user, seed=3068607470).print(orchestration=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we can see the next response is generated based on the previous response, not in the current one. That is, the orchestrator performs the following tasks:\n",
    "1. It uses the previous response (`Previous response: ...`) to get the list of top-k most similar responses from the given list.\n",
    "2. It maps the top-k responses to their corresponding action names (`Actions for the response: ...`)\n",
    "3. For each action in the previous step, it uses the graph to get its next actions.\n",
    "4. Instruct the agent to pick the next response based on the responses associated to the actions from the prevois step.\n",
    "\n",
    "\n",
    "And that's it! we have now our system orchestrator that simulates the STAR original workflow. Let's now move to the user!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### User Agent Orchestration"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Fortunately, the orchestration of the user is much simpler since originally in STAR it only involves providing a series of instructions in order, on specific conversational turns.\n",
    "\n",
    "Let's firs the the original list of instructions given to the user in the dialogue `1`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "user_instructions = STAR.get_dialog_user_instructions(TARGET_DIALOG)\n",
    "user_instructions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here instructions are returned along with the indexes of the turns in which they were provided to the user.\n",
    "\n",
    "We can make use of the built-in `InstructionListOrchestrator` class to orchestrate the user.\n",
    "\n",
    "This orchestrators takes a list of instructions as input and returns one instruction at the time in the given order (or using the provided index to return it when in the right turn).\n",
    "\n",
    "Thus we can simply use it with the list of user instructions to orchestrate the user as follows:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sdialog.orchestrators import InstructionListOrchestrator\n",
    "\n",
    "instr_list_orchestrator = InstructionListOrchestrator(user_instructions, persistent=True)\n",
    "\n",
    "user = user | instr_list_orchestrator"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's now generate the dialogue between our system and user (orchestrated) agents:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dialog = system.talk_with(user, seed=3068607470)\n",
    "dialog.print(orchestration=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Which we can see it is not so different form the original one:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "original_dialog.print(orchestration=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Saving our dialogues"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Before we finish, as we did in the previous tutorials, let's generate one synthetic dialog for each happy `\"doctor_followup\"` dialog in STAR and save it to disk for later use."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm.auto import tqdm\n",
    "\n",
    "PATH_OUTPUT = \"output/STAR/multi-agents+orchestration\"\n",
    "path_txt = os.path.join(PATH_OUTPUT, \"txt\")\n",
    "path_json = os.path.join(PATH_OUTPUT, \"json\")\n",
    "os.makedirs(path_txt, exist_ok=True)\n",
    "os.makedirs(path_json, exist_ok=True)\n",
    "\n",
    "for dialog in tqdm(STAR.get_dialogs(task_name=\"doctor_followup\", happy=True, multitask=False), desc=\"Dialog generation\"):\n",
    "    if os.path.exists(os.path.join(path_txt, f\"{dialog.dialogId}.txt\")):\n",
    "        continue\n",
    "\n",
    "    system, user = STAR.get_agents_from_dialogue_with_orchestration(dialog.dialogId, model_name=MODEL_NAME)\n",
    "\n",
    "    dialog = system.dialog_with(user, id=dialog.dialogId, seed=dialog.dialogId, keep_bar=False)\n",
    "    dialog.to_file(os.path.join(path_json, f\"{dialog.dialogId}.json\"))\n",
    "    dialog.to_file(os.path.join(path_txt, f\"{dialog.dialogId}.txt\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, let's check the files were generated:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%ls output/STAR/multi-agents+orchestration/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise: Doctor-Patient Conversations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Can you replicate the previous tutorial's exercise but this time adding orchestration?\n",
    "\n",
    "1. Define the personas as before\n",
    "2. Create the two agents as before.\n",
    "3. Think of an orchestrator example in this domain, perhaps associated with some attribute of the your `scenario`? (e.g. something happens in the middle of the conversation, doctor or patient realize of doing/saying something?)\n",
    "4. Create your custom orchestrator and add it to the doctor and/or patient.\n",
    "5. Make the two agents talk to each other!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: do your magic!"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
