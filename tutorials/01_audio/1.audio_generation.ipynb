{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tutorial 1: Audio Generation\n",
    "\n",
    "<p align=\"right\" style=\"margin-right: 8px;\">\n",
    "    <a target=\"_blank\" href=\"https://colab.research.google.com/github/idiap/sdialog/blob/main/tutorials/01_audio/1.audio_generation.ipynb\">\n",
    "        <img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/>\n",
    "    </a>\n",
    "</p>\n",
    "\n",
    "## Getting started\n",
    "\n",
    "### Environment Setup\n",
    "\n",
    "Let's first check if our environment is all set up."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setup the environment depending on weather we are running in Google Colab or Jupyter Notebook\n",
    "import os\n",
    "from IPython import get_ipython\n",
    "from IPython.display import Audio, display\n",
    "\n",
    "if \"google.colab\" in str(get_ipython()):\n",
    "    print(\"Running on CoLab\")\n",
    "\n",
    "    # Installing sdialog\n",
    "    !git clone https://github.com/idiap/sdialog.git\n",
    "    %cd sdialog\n",
    "    %pip install -e .[audio]\n",
    "    %cd ..\n",
    "else:\n",
    "    print(\"Running in Jupyter Notebook\")\n",
    "    # Little hack to avoid the \"OSError: Background processes not supported.\" error in Jupyter notebooks\"\n",
    "    get_ipython().system = os.system"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load the example dialogue"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In order to run the next steps in a fast manner, we will start from an existing dialog generated using previous tutorials:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sdialog import Dialog\n",
    "\n",
    "path_dialog = \"../../tests/data/demo_dialog_doctor_patient.json\"\n",
    "\n",
    "if not os.path.exists(path_dialog) and not os.path.exists(\"./demo_dialog_doctor_patient.json\"):\n",
    "    !wget https://raw.githubusercontent.com/idiap/sdialog/refs/heads/main/tests/data/demo_dialog_doctor_patient.json\n",
    "    path_dialog = \"./demo_dialog_doctor_patient.json\"\n",
    "\n",
    "original_dialog = Dialog.from_file(path_dialog)\n",
    "original_dialog.print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tutorial"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Instanciate voices database"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sdialog.audio.voice_database import HuggingfaceVoiceDatabase\n",
    "kokoro_voice_database = HuggingfaceVoiceDatabase(\"sdialog/voices-kokoro\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Instanciate TTS model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install -q kokoro>=0.9.4\n",
    "!apt-get -qq -y install espeak-ng > /dev/null 2>&1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sdialog.audio.tts_engine import KokoroTTS\n",
    "tts_engine = KokoroTTS()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can also try later on some TTS models from the HuggingFace HUB if you want by simply using:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%script false --no-raise-error\n",
    "from sdialog.audio.tts_engine import HuggingFaceTTS\n",
    "tts_engine = HuggingFaceTTS(\"facebook/mms-tts-eng\")  # or any other model from the HuggingFace HUB"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup stage: Audio Dialog and Audio Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sdialog.audio.dialog import AudioDialog\n",
    "from sdialog.audio.pipeline import AudioPipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Convert the original dialog into a audio enhanced dialog"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dialog: AudioDialog = AudioDialog.from_dialog(original_dialog)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Identify speakers names:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Speaker 1:\", dialog.speakers_names[\"speaker_1\"])\n",
    "print(\"Speaker 2:\", dialog.speakers_names[\"speaker_2\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Concatenated utterances with no room accoustics (also called step 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Instanciate the audio pipeline in order to use `Kokoro` (`tts_engine`) as the TTS model and save the outputs of all the dialogs into the directory `./audio_outputs`.\n",
    "\n",
    "The voices are sampled from the `kokoro_voice_database` based on the persona attributes `age`, `gender` and `language`, as assigned during the original textual dialog."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.makedirs(\"./audio_outputs\", exist_ok=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Can be used with default values:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "audio_pipeline = AudioPipeline()\n",
    "dialog: AudioDialog = audio_pipeline.inference(dialog)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display(Audio(dialog.audio_step_1_filepath, autoplay=True, rate=24000))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It will select Kokoro as the default TTS model (with officials voices), save the audio files in `outputs` and run only the step 1 of the pipeline (no room accoustics)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Or by specifying more or less parameters:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "audio_pipeline = AudioPipeline(\n",
    "    voice_database=kokoro_voice_database,\n",
    "    tts_pipeline=tts_engine,\n",
    "    dir_audio=\"./audio_outputs\",\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Perform the inference of the audio pipeline on the previously converted dialog. In this case we will focus on generating the \"unprocessed\" audio, which consist of the agregation of all utterances from the dialog. Rather than using the dialog identifier as the name of the directory, we are using here a custom directory name `demo_dialog_kokoro` which will be saved at `./audio_outputs/demo_dialog_kokoro/`. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate the audio for the dialog\n",
    "dialog: AudioDialog = audio_pipeline.inference(\n",
    "    dialog,\n",
    "    dialog_dir_name=\"demo_dialog_kokoro\",\n",
    ")\n",
    "\n",
    "# Path to the audio of the first stage of the audio pipeline\n",
    "print(\"Audio generated successfully at:\", dialog.audio_step_1_filepath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display(Audio(dialog.audio_step_1_filepath, autoplay=True, rate=24000))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Let's do the same but now by attributing specific voices to the speakers "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sdialog.audio.utils import Role"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate the audio for the dialog\n",
    "dialog: AudioDialog = audio_pipeline.inference(\n",
    "    dialog,\n",
    "    dialog_dir_name=\"demo_dialog_kokoro_selected_voices\",\n",
    "    voices={\n",
    "        Role.SPEAKER_1: (\"am_michael\",\"english\"),\n",
    "        Role.SPEAKER_2: (\"af_bella\",\"english\"),\n",
    "    }\n",
    ")\n",
    "\n",
    "# Path to the audio of the first stage of the audio pipeline\n",
    "print(\"Audio generated successfully at:\", dialog.audio_step_1_filepath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display(Audio(dialog.audio_step_1_filepath, autoplay=True, rate=24000))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generate an audio for a dialogue in one function call ðŸ¤¯"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can also use Dialog internal function to convert the dialogue into a AudioDialog with the audio files:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_audio_dialog = original_dialog.to_audio()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display(Audio(new_audio_dialog.audio_step_1_filepath, autoplay=True, rate=24000))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Or by using the utility function `to_audio` which share the same parameters as the internal method to the Dialog object:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sdialog.audio.pipeline import to_audio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_audio_dialog = to_audio(\n",
    "    original_dialog,\n",
    "    audio_file_format=\"mp3\", # can also be generated with mp3 / wav / flac formats\n",
    "    re_sampling_rate=16000,\n",
    "    dialog_dir_name=\"utility_function_demo\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display(Audio(new_audio_dialog.audio_step_1_filepath, autoplay=True, rate=16000))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
