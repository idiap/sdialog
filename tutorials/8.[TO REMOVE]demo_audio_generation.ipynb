{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# On Jean Zay HPC"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```bash\n",
    "module purge\n",
    "\n",
    "module load arch/h100\n",
    "module load cuda/12.4.1\n",
    "module load ffmpeg/6.1.1\n",
    "\n",
    "module load miniforge\n",
    "\n",
    "conda activate jsalt10\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you want to perform dScaper and PyRoomAcoustics (steps 2 and 3):\n",
    "```bash\n",
    "cd ./dscaper\n",
    "pip install -e .\n",
    "\n",
    "conda install sox\n",
    "pip install sox\n",
    "\n",
    "pip install jams\n",
    "pip install pyloudnorm\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SDialog dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%script false --no-raise-error\n",
    "# Only run this cell if you are using a non jupyter environment\n",
    "!conda create --name jsalt python=3.9 -y\n",
    "!conda activate jsalt\n",
    "!conda install sox\n",
    "!pip install -r sdialog/requirements.txt\n",
    "!pip install -r sdialog/requirements-audio.txt\n",
    "#  conda activate jsalt-Py3-10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sdialog\n",
    "from sdialog import Dialog\n",
    "from sdialog.generators import PersonaGenerator\n",
    "from sdialog.personas import Persona, PersonaAgent, Doctor, Patient, Agent"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generate Persona"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sdialog.config.set_llm(\"aws:anthropic.claude-3-5-sonnet-20240620-v1:0\", region_name=\"us-east-1\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%script false --no-raise-error\n",
    "persona_card_folder = \"./personas\"\n",
    "\n",
    "# Generate doctor persona\n",
    "doctor_persona = Doctor(\n",
    "    name=\"Dr. Smith\",\n",
    "    gender=\"male\",\n",
    "    age=52,\n",
    "    specialty=\"Family Medicine\"\n",
    ")\n",
    "generator_doctor = PersonaGenerator(doctor_persona)\n",
    "persona_cards = generator_doctor.generate(n=1)\n",
    "persona_cards.to_file(f\"{persona_card_folder}/persona_doctor.json\")\n",
    "\n",
    "# Generate patient persona\n",
    "patient_persona = Patient(\n",
    "    name=\"John Doe\",\n",
    "    gender=\"male\",\n",
    "    age=62\n",
    ")\n",
    "generator_patient = PersonaGenerator(patient_persona)\n",
    "persona_cards = generator_patient.generate(n=1)\n",
    "persona_cards.to_file(f\"{persona_card_folder}/persona_patient.json\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load persona"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load personas\n",
    "persona_doctor = Persona.from_file(\"./personas/persona_doctor.json\")\n",
    "persona_patient = Persona.from_file(\"./personas/persona_patient.json\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%script false --no-raise-error\n",
    "context = \"Generate me a 50 turn medical dialogue between patient and doctor, for a primary care visit\"\n",
    "\n",
    "# Create agents\n",
    "agent1 = PersonaAgent(persona=persona_doctor, name=\"DOCTOR\", dialogue_details=context, response_details=\"make short turn answers when needed\")\n",
    "agent2 = PersonaAgent(persona=persona_patient, name=\"PATIENT\", dialogue_details=context, response_details=\"make short turn answers when needed\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_all = True\n",
    "GENERATE_PERSONA = True\n",
    "FORCE_DIALOG_GENERATION = False\n",
    "\n",
    "os.makedirs(\"./outputs\", exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if FORCE_DIALOG_GENERATION:\n",
    "\n",
    "    original_dialog = agent1.talk_with(agent2, max_turns=3)\n",
    "    original_dialog.to_file(\"dialog_demo.json\")\n",
    "\n",
    "else:\n",
    "    original_dialog = Dialog.from_file(\"dialog_demo.json\")\n",
    "\n",
    "original_dialog.print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Audio Generation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can generate three type of audios:\n",
    "- (default) Step 1: Raw utterances passed to a TTS model and concatenated to each others to create an audio file\n",
    "- Step 2: Audio generated from multiple channels create using signal positions\n",
    "- Step 3: Audio generated using room spacialization and multi-channels positions\n",
    "\n",
    "If you want to trigger the \"step 2\" you need to give a Scaper argument to the `audio_pipeline`. While for the \"step 3\" you need also to give a \"Room\" in the `inference` function."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Instanciate voices database"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sdialog.audio.voice_database import DummyKokoroVoiceDatabase\n",
    "dummy_voice_database = DummyKokoroVoiceDatabase()\n",
    "dummy_voice_database.get_voice(genre=\"male\", age=20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "OR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%script false --no-raise-error\n",
    "from sdialog.audio.voice_database import HuggingfaceVoiceDatabase\n",
    "voices_libritts = HuggingfaceVoiceDatabase(\"sdialog/voices-libritts\")\n",
    "voices_libritts.get_voice(genre=\"male\", age=20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "OR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%script false --no-raise-error\n",
    "from sdialog.audio.voice_database import HuggingfaceVoiceDatabase\n",
    "dummy_voice_database = HuggingfaceVoiceDatabase(\"sdialog/voices-jsalt\")\n",
    "dummy_voice_database.get_voice(genre=\"male\", age=20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Instanciate TTS model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sdialog.audio.tts_engine import KokoroTTS\n",
    "tts_pipeline = KokoroTTS()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%script false --no-raise-error\n",
    "##################################################\n",
    "# DOESN'T WORK ON MULTILINGUAL MACOS\n",
    "##################################################\n",
    "\n",
    "# Generate multilingual audio from text using the Kokoro model\n",
    "\n",
    "from sdialog.audio.tts_engine import KokoroTTS\n",
    "\n",
    "tts_pipeline = KokoroTTS(lang_code=\"f\")\n",
    "# tts_pipeline = KokoroTTS(lang_code=\"a\")\n",
    "\n",
    "from phonemizer.backend.espeak.wrapper import EspeakWrapper\n",
    "_ESPEAK_LIBRARY = '/opt/homebrew/Cellar/espeak/1.48.04_1/lib/libespeak.1.1.48.dylib'\n",
    "EspeakWrapper.set_library(_ESPEAK_LIBRARY)\n",
    "\n",
    "import soundfile\n",
    "audio, sampling_rate = tts_pipeline.generate(\n",
    "    # \"Hi, how are you today?\",\n",
    "    # \"af_alloy\"\n",
    "    \"Bonjour, comment Ã§a va?\",\n",
    "    \"ff_siwis\"\n",
    ")\n",
    "print(audio)\n",
    "print(sampling_rate)\n",
    "output_file_name = \"./test_index_tts_french.wav\"\n",
    "soundfile.write(output_file_name, audio, sampling_rate)\n",
    "print(f\"Audio saved to {output_file_name}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "OR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%script false --no-raise-error\n",
    "from sdialog.audio.tts_engine import IndexTTS\n",
    "tts_pipeline = IndexTTS(device=\"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%script false --no-raise-error\n",
    "# Generate audio from text using the IndexTTS model\n",
    "import soundfile\n",
    "audio, sampling_rate = tts_pipeline.generate(\n",
    "    \"Brno is the best city in the planet, you know? and Loco Polaco is the craziest person I know\",\n",
    "    \"./sergio.wav\"\n",
    ")\n",
    "soundfile.write(\"./test_index_tts.wav\", audio, sampling_rate)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup stage: Audio Dialog and Audio Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sdialog.audio.audio_dialog import AudioDialog\n",
    "from sdialog.audio.audio_pipeline import AudioPipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dialog: AudioDialog = AudioDialog.from_dialog(original_dialog)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 1 : Concatenated utterances"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "audio_pipeline = AudioPipeline(\n",
    "    voice_database=dummy_voice_database,\n",
    "    tts_pipeline=tts_pipeline,\n",
    "    dir_audio=\"./outputs\",\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "OR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%script false --no-raise-error\n",
    "audio_pipeline = AudioPipeline() # Default values are used"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dialog: AudioDialog = audio_pipeline.inference(dialog) # Generate the audio for the dialog\n",
    "print(dialog.audio_step_1_filepath) # Path to the audio of the first stage of the audio pipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 2: dScaper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%script false --no-raise-error\n",
    "!git clone https://github.com/cyrta/dscaper.git"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%script false --no-raise-error\n",
    "%pip install -r ../../../requirements-dscaper.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import scaper\n",
    "DATA_PATH = \"./dscaper_data\" # Path where the sound events, utterances and timelines database will be saved\n",
    "os.makedirs(DATA_PATH, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dsc = scaper.Dscaper(dscaper_base_path=DATA_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "audio_pipeline = AudioPipeline(dscaper=dsc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Populate the sound events database\n",
    "audio_pipeline.populate_dscaper([\"sdialog/background\",\"sdialog/foreground\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dialog: AudioDialog = audio_pipeline.inference(dialog)\n",
    "print(dialog.audio_step_1_filepath)\n",
    "print(dialog.audio_step_2_filepath)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 3 : Room Accoustics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "audio_pipeline = AudioPipeline(dscaper=dsc) # The audio pipeline doesn't change"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sdialog.audio.room import MicrophonePosition\n",
    "from sdialog.audio.room_generator import RoomGenerator, RoomRole"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "room = RoomGenerator().generate(RoomRole.CONSULTATION, room_size=8.0)\n",
    "print(room)\n",
    "print(\"--------------------------------\")\n",
    "print(room.name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dialog: AudioDialog = AudioDialog.from_dialog(original_dialog)\n",
    "dialog: AudioDialog = audio_pipeline.inference(\n",
    "    dialog,\n",
    "    room=room, # Need to provide a room object to trigger the 3rd step of the audio pipeline\n",
    "    # microphone_position=MicrophonePosition.MONITOR # Default is MicrophonePosition.MONITOR\n",
    "    microphone_position=MicrophonePosition.CEILING_CENTERED, # Default is MicrophonePosition.MONITOR\n",
    "    do_step_1=True,\n",
    "    do_step_2=False,\n",
    "    do_step_3=False,\n",
    ")\n",
    "print(dialog.audio_step_1_filepath)\n",
    "print(dialog.audio_step_2_filepath)\n",
    "print(dialog.audio_step_3_filepaths)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Custom dialog directory names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dialog: AudioDialog = AudioDialog.from_dialog(original_dialog)\n",
    "dialog: AudioDialog = audio_pipeline.inference(\n",
    "    dialog,\n",
    "    room=room, # Need to provide a room object to trigger the 3rd step of the audio pipeline\n",
    "    # microphone_position=MicrophonePosition.MONITOR # Default is MicrophonePosition.MONITOR\n",
    "    microphone_position=MicrophonePosition.CEILING_CENTERED, # Default is MicrophonePosition.MONITOR\n",
    "    do_step_1=True,\n",
    "    do_step_2=True,\n",
    "    do_step_3=True,\n",
    "    dialog_dir_name=\"demo_dialog\"\n",
    ")\n",
    "print(dialog.audio_step_1_filepath)\n",
    "print(dialog.audio_step_2_filepath)\n",
    "print(dialog.audio_step_3_filepaths)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Custom room accoustic audio file name\n",
    "\n",
    "You can customize the name of the file in order to fit with the setup of the room, microphone position and so on."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dialog: AudioDialog = AudioDialog.from_dialog(original_dialog)\n",
    "dialog: AudioDialog = audio_pipeline.inference(\n",
    "    dialog,\n",
    "    room=room, # Need to provide a room object to trigger the 3rd step of the audio pipeline\n",
    "    # microphone_position=MicrophonePosition.MONITOR # Default is MicrophonePosition.MONITOR\n",
    "    microphone_position=MicrophonePosition.CEILING_CENTERED, # Default is MicrophonePosition.MONITOR\n",
    "    do_step_1=False,\n",
    "    do_step_2=False,\n",
    "    do_step_3=True,\n",
    "    dialog_dir_name=\"demo_dialog\",\n",
    "    room_name=\"my_room_acc_1\"\n",
    ")\n",
    "print(dialog.audio_step_1_filepath)\n",
    "print(dialog.audio_step_2_filepath)\n",
    "print(dialog.audio_step_3_filepaths)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "jsalt",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.23"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
