{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b73e6234",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/yanislabrak/opt/miniconda3/envs/jsalt/lib/python3.9/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from tqdm import tqdm\n",
    "from datasets import load_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0267fd24",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Repo card metadata block was not found. Setting CardData to empty.\n"
     ]
    }
   ],
   "source": [
    "hf_dataset = \"sdialog/voices-libritts\"\n",
    "dataset = load_dataset(hf_dataset)[\"train\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "22b047c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyannote.audio import Model, Inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e1733c7c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/yanislabrak/opt/miniconda3/envs/jsalt/lib/python3.9/site-packages/pytorch_lightning/utilities/migration/migration.py:208: You have multiple `ModelCheckpoint` callback states in this checkpoint, but we found state keys that would end up colliding with each other after an upgrade, which means we can't differentiate which of your checkpoint callbacks needs which states. At least one of your `ModelCheckpoint` callbacks will not be able to reload the state.\n",
      "Lightning automatically upgraded your loaded checkpoint from v1.2.7 to v2.5.2. To apply the upgrade to your files permanently, run `python -m pytorch_lightning.utilities.upgrade_checkpoint ../../../../../../../.cache/torch/pyannote/models--pyannote--embedding/snapshots/4db4899737a38b2d618bbd74350915aa10293cb2/pytorch_model.bin`\n",
      "/Users/yanislabrak/opt/miniconda3/envs/jsalt/lib/python3.9/site-packages/pyannote/audio/core/model.py:692: UserWarning: Model has been trained with a task-dependent loss function. Set 'strict' to False to load the model without its loss function and prevent this warning from appearing. \n",
      "  warnings.warn(msg)\n",
      "Lightning automatically upgraded your loaded checkpoint from v1.2.7 to v2.5.2. To apply the upgrade to your files permanently, run `python -m pytorch_lightning.utilities.upgrade_checkpoint ../../../../../../../.cache/torch/pyannote/models--pyannote--embedding/snapshots/4db4899737a38b2d618bbd74350915aa10293cb2/pytorch_model.bin`\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model was trained with pyannote.audio 0.0.1, yours is 3.3.2. Bad things might happen unless you revert pyannote.audio to 0.x.\n",
      "Model was trained with torch 1.8.1+cu102, yours is 2.2.2. Bad things might happen unless you revert torch to 1.x.\n",
      "Model was trained with pyannote.audio 0.0.1, yours is 3.3.2. Bad things might happen unless you revert pyannote.audio to 0.x.\n",
      "Model was trained with torch 1.8.1+cu102, yours is 2.2.2. Bad things might happen unless you revert torch to 1.x.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/yanislabrak/opt/miniconda3/envs/jsalt/lib/python3.9/site-packages/pytorch_lightning/core/saving.py:195: Found keys that are not in the model state dict but in the checkpoint: ['loss_func.W']\n"
     ]
    }
   ],
   "source": [
    "pyannote_model = Model.from_pretrained(\"pyannote/embedding\")\n",
    "inference = Inference(pyannote_model, window=\"whole\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7490594e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'speaker_id': 14,\n",
       " 'gender': 'F',\n",
       " 'name': 'Kristin LeMoine',\n",
       " 'subset': 'train-clean-360',\n",
       " 'age': -1,\n",
       " 'audio': {'path': '/Users/yanislabrak/.cache/huggingface/hub/datasets--sdialog--voices-libritts/snapshots/69cc148ad7799e2a8889dd4d3fb9309c28e97435/audio/14_Kristin_LeMoine.wav',\n",
       "  'array': array([ 0.        ,  0.00015259, -0.00012207, ..., -0.00262451,\n",
       "         -0.01190186, -0.00335693]),\n",
       "  'sampling_rate': 24000},\n",
       " 'total_duration_s': 30.0,\n",
       " 'used_utterances': '[{\"path\": \"/lustre/fsmisc/dataset/LibriTTS/train-clean-360/14/208/14_208_000001_000000.wav\", \"duration_s\": 9.02}, {\"path\": \"/lustre/fsmisc/dataset/LibriTTS/train-clean-360/14/208/14_208_000001_000002.wav\", \"duration_s\": 21.61}]'}"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb50b94f",
   "metadata": {},
   "outputs": [],
   "source": [
    "xvectors = {}\n",
    "\n",
    "for d in tqdm(dataset):\n",
    "    embedding = inference(d[\"audio\"][\"path\"])\n",
    "    xvectors[d[\"speaker_id\"]] = embedding"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "jsalt",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.23"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
