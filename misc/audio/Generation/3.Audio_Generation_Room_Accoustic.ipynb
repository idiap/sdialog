{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SDialog dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/yanislabrak/opt/miniconda3/envs/jsalt/lib/python3.9/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import sdialog\n",
    "from sdialog import Dialog"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load dialog"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m\u001b[95m[dialog_id] \u001b[35m1752861530588\u001b[0m\n",
      "\u001b[1m\u001b[95m[model] \u001b[35mclient=<botocore.client.BedrockRuntime object at 0x7fc319ec91c0> model_id='anthropic.claude-3-5-sonnet-20240620-v1:0' region_name='us-east-1' provider='anthropic' supports_tool_choice_values=('auto', 'any', 'tool')\u001b[0m\n",
      "\u001b[1m\u001b[95m[seed] \u001b[35m226296126\u001b[0m\n",
      "\u001b[1m\u001b[35m--- Dialogue Begins ---\u001b[0m\n",
      "\u001b[31m[DOCTOR] \u001b[0mHello there. I'm Dr. Smith. Welcome to my office. What brings you in to see me today?\u001b[0m\n",
      "\u001b[94m[PATIENT] \u001b[37mGood morning, Dr. Smith. I'm John Doe. I've been dealing with a persistent cough and feeling pretty tired for about three weeks now. It's starting to wear me down, and I thought I should get it checked out.\u001b[0m\n",
      "\u001b[31m[DOCTOR] \u001b[0mI'm sorry to hear you've been feeling unwell, Mr. Doe. A persistent cough and fatigue can certainly be troublesome. Let's get some more details. Can you describe your cough? Is it dry or productive?\u001b[0m\n",
      "\u001b[94m[PATIENT] \u001b[37mWell, Dr. Smith, it's mostly a dry cough. It's particularly bothersome at night when I'm trying to sleep. You know, it reminds me of the time I was teaching about the Civil War and how soldiers often suffered from \"camp cough\" due to poor conditions. Of course, I doubt my situation is that dire, but it's certainly annoying.\u001b[0m\n",
      "\u001b[1m\u001b[35m--- Dialogue Ends ---\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "original_dialog = Dialog.from_file(\"dialog_demo.json\")\n",
    "original_dialog.print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Audio Generation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Instanciate voices database"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'identifier': 'am_fenrir', 'voice': 'am_fenrir'}"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sdialog.audio.voice_database import DummyKokoroVoiceDatabase\n",
    "dummy_voice_database = DummyKokoroVoiceDatabase()\n",
    "dummy_voice_database.get_voice(genre=\"male\", age=20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Instanciate TTS model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/yanislabrak/opt/miniconda3/envs/jsalt/lib/python3.9/site-packages/torch/nn/modules/rnn.py:83: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.2 and num_layers=1\n",
      "  warnings.warn(\"dropout option adds dropout after all but last \"\n",
      "/Users/yanislabrak/opt/miniconda3/envs/jsalt/lib/python3.9/site-packages/torch/nn/utils/weight_norm.py:28: UserWarning: torch.nn.utils.weight_norm is deprecated in favor of torch.nn.utils.parametrizations.weight_norm.\n",
      "  warnings.warn(\"torch.nn.utils.weight_norm is deprecated in favor of torch.nn.utils.parametrizations.weight_norm.\")\n"
     ]
    }
   ],
   "source": [
    "from sdialog.audio.tts_engine import KokoroTTS\n",
    "tts_engine = KokoroTTS()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup stage: Audio Dialog and Audio Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sdialog.audio.audio_dialog import AudioDialog\n",
    "from sdialog.audio.audio_pipeline import AudioPipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Convert the original dialog into a audio enhanced dialog"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "dialog: AudioDialog = AudioDialog.from_dialog(original_dialog)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Instanciate the audio pipeline in order to use `Kokoro` (`tts_engine`) as the TTS model and save the outputs of all the dialogs into the directory `./outputs`.\n",
    "\n",
    "The voices are sampled from the `dummy_voice_database` based on the persona attributes `age` and `gender`, as assigned during the original textual dialog."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%script false --no-raise-error\n",
    "!git clone https://github.com/cyrta/dscaper.git\n",
    "%pip install -r ../../../requirements-dscaper.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import scaper\n",
    "DATA_PATH = \"./dscaper_data\" # Path where the sound events, utterances and timelines database will be saved\n",
    "os.makedirs(DATA_PATH, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "dsc = scaper.Dscaper(dscaper_base_path=DATA_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.makedirs(\"./outputs\", exist_ok=True)\n",
    "audio_pipeline = AudioPipeline(\n",
    "    voice_database=dummy_voice_database,\n",
    "    tts_pipeline=tts_engine,\n",
    "    dscaper=dsc,\n",
    "    dir_audio=\"./outputs\",\n",
    ")\n",
    "# audio_pipeline = AudioPipeline() # Can also be used with default values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Populating dSCAPER with sdialog/background dataset...: 100%|██████████| 4/4 [00:01<00:00,  2.42it/s]\n",
      "Populating dSCAPER with sdialog/foreground dataset...: 100%|██████████| 8/8 [00:00<00:00, 20.87it/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'count_existing_audio_files': 12,\n",
       " 'count_error_audio_files': 0,\n",
       " 'count_success_audio_files': 0}"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Populate the sound events database\n",
    "audio_pipeline.populate_dscaper([\"sdialog/background\",\"sdialog/foreground\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sdialog.audio.room_generator import RoomGenerator, RoomRole"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1036:  consultation_room, desc: consultation room (dimentions: dim: [3.577708763999664, 2.23606797749979, 3.0], rt60: 0.5) role: consultation)  \n"
     ]
    }
   ],
   "source": [
    "room = RoomGenerator().generate(RoomRole.CONSULTATION, room_size=8.0)\n",
    "print(room)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Perform the inference of the audio pipeline on the previously converted dialog. In this case we will focus on generating the \"unprocessed\" audio, which consist of the agregation of all utterances from the dialog. Rather than using the dialog identifier as the name of the directory, we are using here a custom directory name `demo_dialog_kokoro` which will be saved at `./outputs/demo_dialog_kokoro/`. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sdialog.audio.room import MicrophonePosition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2025-09-29 23:25:56] INFO:root:Dialog audio dir path: ./outputs\n",
      "[2025-09-29 23:25:56] INFO:root:Audio dialog loaded from the existing file (1752861530588) successfully!\n",
      "[2025-09-29 23:25:56] INFO:root:Audio sources from dSCAPER loaded in the dialog (1752861530588) successfully!\n",
      "[2025-09-29 23:25:56] INFO:root:Generating room accoustic for dialogue 1752861530588\n",
      "[2025-09-29 23:25:56] INFO:root:  Microphone set to position [0.9944271909999159, 0.33541019662496846, 1.2]\n",
      "[2025-09-29 23:25:56] INFO:root:  Microphone set to position [1.788854381999832, 1.118033988749895, 2.9]\n",
      "[2025-09-29 23:25:56] INFO:root:✓ Loaded audio file './dscaper_data/timelines/demo_dialog_room_accoustic/generate/b426e1ad-50d5-49a4-96b2-d9f06d3d1732/soundscape_positions/no_type.wav' for 'no_type' with 1918350 samples\n",
      "[2025-09-29 23:25:56] INFO:root:✓ Loaded audio file './dscaper_data/timelines/demo_dialog_room_accoustic/generate/b426e1ad-50d5-49a4-96b2-d9f06d3d1732/soundscape_positions/doctor-at_desk_sitting.wav' for 'doctor-at_desk_sitting' with 1918350 samples\n",
      "[2025-09-29 23:25:56] INFO:root:✓ Loaded audio file './dscaper_data/timelines/demo_dialog_room_accoustic/generate/b426e1ad-50d5-49a4-96b2-d9f06d3d1732/soundscape_positions/patient-next_to_desk_sitting.wav' for 'patient-next_to_desk_sitting' with 1918350 samples\n",
      "[2025-09-29 23:25:57] WARNING:root:Room 'my_room_config_1' already exists in the dialog\n",
      "[2025-09-29 23:25:57] INFO:root:Room accoustic generated for dialogue 1752861530588!\n",
      "[2025-09-29 23:25:57] INFO:root:Audio dialog saved to the existing file (1752861530588) successfully at the end of the pipeline!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "./outputs/demo_dialog_room_accoustic/exported_audios/audio_pipeline_step1.wav\n",
      "./outputs/demo_dialog_room_accoustic/exported_audios/audio_pipeline_step2.wav\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'jdialog' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[18], line 13\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[38;5;28mprint\u001b[39m(dialog\u001b[38;5;241m.\u001b[39maudio_step_1_filepath)\n\u001b[1;32m     12\u001b[0m \u001b[38;5;28mprint\u001b[39m(dialog\u001b[38;5;241m.\u001b[39maudio_step_2_filepath)\n\u001b[0;32m---> 13\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[43mjdialog\u001b[49m\u001b[38;5;241m.\u001b[39maudio_step_3_filepaths)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'jdialog' is not defined"
     ]
    }
   ],
   "source": [
    "dialog: AudioDialog = audio_pipeline.inference(\n",
    "    dialog,\n",
    "    room=room, # Need to provide a room object to trigger the 3rd step of the audio pipeline\n",
    "    microphone_position=MicrophonePosition.CEILING_CENTERED, # Default is MicrophonePosition.MONITOR\n",
    "    do_step_1=True,\n",
    "    do_step_2=True,\n",
    "    do_step_3=True,\n",
    "    dialog_dir_name=\"demo_dialog_room_accoustic\",\n",
    "    room_name=\"my_room_config_1\"\n",
    ")\n",
    "print(dialog.audio_step_1_filepath)\n",
    "print(dialog.audio_step_2_filepath)\n",
    "print(dialog.audio_step_3_filepaths)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "jsalt",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.23"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
