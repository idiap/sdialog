{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# On Jean Zay HPC"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```bash\n",
    "module purge\n",
    "\n",
    "module load arch/h100\n",
    "module load cuda/12.4.1\n",
    "module load ffmpeg/6.1.1\n",
    "\n",
    "module load miniforge\n",
    "\n",
    "conda activate jsalt10\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you want to perform dScaper and PyRoomAcoustics (steps 2 and 3):\n",
    "```bash\n",
    "cd ./dscaper\n",
    "pip install -e .\n",
    "\n",
    "conda install sox\n",
    "pip install sox\n",
    "\n",
    "pip install jams\n",
    "pip install pyloudnorm\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SDialog dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%script false --no-raise-error\n",
    "# Only run this cell if you are using a non jupyter environment\n",
    "!conda create --name jsalt python=3.9 -y\n",
    "!conda activate jsalt\n",
    "!conda install sox\n",
    "!pip install -r sdialog/requirements.txt\n",
    "!pip install -r sdialog/requirements-audio.txt\n",
    "#  conda activate jsalt-Py3-10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/yanislabrak/opt/miniconda3/envs/jsalt/lib/python3.9/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import sdialog\n",
    "from sdialog import Dialog\n",
    "from sdialog.generators import PersonaGenerator\n",
    "from sdialog.personas import Persona, PersonaAgent, Doctor, Patient, Agent"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generate Persona"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "sdialog.config.set_llm(\"aws:anthropic.claude-3-5-sonnet-20240620-v1:0\", region_name=\"us-east-1\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%script false --no-raise-error\n",
    "persona_card_folder = \"./personas\"\n",
    "\n",
    "# Generate doctor persona\n",
    "doctor_persona = Doctor(\n",
    "    name=\"Dr. Smith\",\n",
    "    gender=\"male\",\n",
    "    age=52,\n",
    "    specialty=\"Family Medicine\"\n",
    ")\n",
    "generator_doctor = PersonaGenerator(doctor_persona)\n",
    "persona_cards = generator_doctor.generate(n=1)\n",
    "persona_cards.to_file(f\"{persona_card_folder}/persona_doctor.json\")\n",
    "\n",
    "# Generate patient persona\n",
    "patient_persona = Patient(\n",
    "    name=\"John Doe\",\n",
    "    gender=\"male\",\n",
    "    age=62\n",
    ")\n",
    "generator_patient = PersonaGenerator(patient_persona)\n",
    "persona_cards = generator_patient.generate(n=1)\n",
    "persona_cards.to_file(f\"{persona_card_folder}/persona_patient.json\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load persona"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load personas\n",
    "persona_doctor = Persona.from_file(\"./personas/persona_doctor.json\")\n",
    "persona_patient = Persona.from_file(\"./personas/persona_patient.json\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%script false --no-raise-error\n",
    "context = \"Generate me a 50 turn medical dialogue between patient and doctor, for a primary care visit\"\n",
    "\n",
    "# Create agents\n",
    "agent1 = PersonaAgent(persona=persona_doctor, name=\"DOCTOR\", dialogue_details=context, response_details=\"make short turn answers when needed\")\n",
    "agent2 = PersonaAgent(persona=persona_patient, name=\"PATIENT\", dialogue_details=context, response_details=\"make short turn answers when needed\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_all = True\n",
    "GENERATE_PERSONA = True\n",
    "FORCE_DIALOG_GENERATION = False\n",
    "\n",
    "os.makedirs(\"./outputs\", exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m\u001b[95m[dialog_id] \u001b[35m1752861530588\u001b[0m\n",
      "\u001b[1m\u001b[95m[model] \u001b[35mclient=<botocore.client.BedrockRuntime object at 0x7fc319ec91c0> model_id='anthropic.claude-3-5-sonnet-20240620-v1:0' region_name='us-east-1' provider='anthropic' supports_tool_choice_values=('auto', 'any', 'tool')\u001b[0m\n",
      "\u001b[1m\u001b[95m[seed] \u001b[35m226296126\u001b[0m\n",
      "\u001b[1m\u001b[35m--- Dialogue Begins ---\u001b[0m\n",
      "\u001b[31m[DOCTOR] \u001b[0mHello there. I'm Dr. Smith. Welcome to my office. What brings you in to see me today?\u001b[0m\n",
      "\u001b[94m[PATIENT] \u001b[37mGood morning, Dr. Smith. I'm John Doe. I've been dealing with a persistent cough and feeling pretty tired for about three weeks now. It's starting to wear me down, and I thought I should get it checked out.\u001b[0m\n",
      "\u001b[31m[DOCTOR] \u001b[0mI'm sorry to hear you've been feeling unwell, Mr. Doe. A persistent cough and fatigue can certainly be troublesome. Let's get some more details. Can you describe your cough? Is it dry or productive?\u001b[0m\n",
      "\u001b[94m[PATIENT] \u001b[37mWell, Dr. Smith, it's mostly a dry cough. It's particularly bothersome at night when I'm trying to sleep. You know, it reminds me of the time I was teaching about the Civil War and how soldiers often suffered from \"camp cough\" due to poor conditions. Of course, I doubt my situation is that dire, but it's certainly annoying.\u001b[0m\n",
      "\u001b[1m\u001b[35m--- Dialogue Ends ---\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "if FORCE_DIALOG_GENERATION:\n",
    "\n",
    "    original_dialog = agent1.talk_with(agent2, max_turns=3)\n",
    "    original_dialog.to_file(\"dialog_demo.json\")\n",
    "\n",
    "else:\n",
    "    original_dialog = Dialog.from_file(\"dialog_demo.json\")\n",
    "\n",
    "original_dialog.print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Audio Generation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can generate three type of audios:\n",
    "- (default) Step 1: Raw utterances passed to a TTS model and concatenated to each others to create an audio file\n",
    "- Step 2: Audio generated from multiple channels create using signal positions\n",
    "- Step 3: Audio generated using room spacialization and multi-channels positions\n",
    "\n",
    "If you want to trigger the \"step 2\" you need to give a Scaper argument to the `audio_pipeline`. While for the \"step 3\" you need also to give a \"Room\" in the `inference` function."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Instanciate voices database"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'identifier': 'am_echo', 'voice': 'am_echo'}"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sdialog.audio.voice_database import DummyKokoroVoiceDatabase\n",
    "dummy_voice_database = DummyKokoroVoiceDatabase()\n",
    "dummy_voice_database.get_voice(genre=\"male\", age=20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "OR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%script false --no-raise-error\n",
    "from sdialog.audio.voice_database import HuggingfaceVoiceDatabase\n",
    "voices_libritts = HuggingfaceVoiceDatabase(\"sdialog/voices-libritts\")\n",
    "voices_libritts.get_voice(genre=\"male\", age=20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "OR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%script false --no-raise-error\n",
    "from sdialog.audio.voice_database import HuggingfaceVoiceDatabase\n",
    "dummy_voice_database = HuggingfaceVoiceDatabase(\"sdialog/voices-jsalt\")\n",
    "dummy_voice_database.get_voice(genre=\"male\", age=20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Instanciate TTS model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/yanislabrak/opt/miniconda3/envs/jsalt/lib/python3.9/site-packages/torch/nn/modules/rnn.py:83: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.2 and num_layers=1\n",
      "  warnings.warn(\"dropout option adds dropout after all but last \"\n",
      "/Users/yanislabrak/opt/miniconda3/envs/jsalt/lib/python3.9/site-packages/torch/nn/utils/weight_norm.py:28: UserWarning: torch.nn.utils.weight_norm is deprecated in favor of torch.nn.utils.parametrizations.weight_norm.\n",
      "  warnings.warn(\"torch.nn.utils.weight_norm is deprecated in favor of torch.nn.utils.parametrizations.weight_norm.\")\n"
     ]
    }
   ],
   "source": [
    "from sdialog.audio.tts_engine import KokoroTTS\n",
    "tts_pipeline = KokoroTTS()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%script false --no-raise-error\n",
    "##################################################\n",
    "# DOESN'T WORK ON MULTILINGUAL MACOS\n",
    "##################################################\n",
    "\n",
    "# Generate multilingual audio from text using the Kokoro model\n",
    "\n",
    "from sdialog.audio.tts_engine import KokoroTTS\n",
    "\n",
    "tts_pipeline = KokoroTTS(lang_code=\"f\")\n",
    "# tts_pipeline = KokoroTTS(lang_code=\"a\")\n",
    "\n",
    "from phonemizer.backend.espeak.wrapper import EspeakWrapper\n",
    "_ESPEAK_LIBRARY = '/opt/homebrew/Cellar/espeak/1.48.04_1/lib/libespeak.1.1.48.dylib'\n",
    "EspeakWrapper.set_library(_ESPEAK_LIBRARY)\n",
    "\n",
    "import soundfile\n",
    "audio, sampling_rate = tts_pipeline.generate(\n",
    "    # \"Hi, how are you today?\",\n",
    "    # \"af_alloy\"\n",
    "    \"Bonjour, comment ça va?\",\n",
    "    \"ff_siwis\"\n",
    ")\n",
    "print(audio)\n",
    "print(sampling_rate)\n",
    "output_file_name = \"./test_index_tts_french.wav\"\n",
    "soundfile.write(output_file_name, audio, sampling_rate)\n",
    "print(f\"Audio saved to {output_file_name}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "OR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%script false --no-raise-error\n",
    "from sdialog.audio.tts_engine import IndexTTS\n",
    "tts_pipeline = IndexTTS(device=\"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%script false --no-raise-error\n",
    "# Generate audio from text using the IndexTTS model\n",
    "import soundfile\n",
    "audio, sampling_rate = tts_pipeline.generate(\n",
    "    \"Brno is the best city in the planet, you know? and Loco Polaco is the craziest person I know\",\n",
    "    \"./sergio.wav\"\n",
    ")\n",
    "soundfile.write(\"./test_index_tts.wav\", audio, sampling_rate)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup stage: Audio Dialog and Audio Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sdialog.audio.audio_dialog import AudioDialog\n",
    "from sdialog.audio.audio_pipeline import AudioPipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "dialog: AudioDialog = AudioDialog.from_dialog(original_dialog)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 1 : Concatenated utterances"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "audio_pipeline = AudioPipeline(\n",
    "    voice_database=dummy_voice_database,\n",
    "    tts_pipeline=tts_pipeline,\n",
    "    dir_audio=\"./outputs\",\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "OR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%script false --no-raise-error\n",
    "audio_pipeline = AudioPipeline() # Default values are used"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2025-09-27 20:47:24] WARNING:root:The dSCAPER is not set, which make the generation of the timeline impossible\n",
      "[2025-09-27 20:47:24] WARNING:root:The room or the dSCAPER is not set, which make the generation of the room accoustic audio impossible\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "./outputs/dialog_1752861530588/exported_audios/audio_pipeline_step1.wav\n",
      "Loading utterances and combined audio from dialogue 1752861530588\n",
      "Audio data from step 1 loaded into the dialog (1752861530588) successfully!\n",
      "./outputs/dialog_1752861530588/exported_audios/audio_pipeline_step1.wav\n"
     ]
    }
   ],
   "source": [
    "dialog: AudioDialog = audio_pipeline.inference(dialog) # Generate the audio for the dialog\n",
    "print(dialog.audio_step_1_filepath) # Path to the audio of the first stage of the audio pipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 2: dScaper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%script false --no-raise-error\n",
    "!git clone https://github.com/cyrta/dscaper.git"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%script false --no-raise-error\n",
    "%pip install -r ../../../requirements-dscaper.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "import scaper\n",
    "DATA_PATH = \"./dscaper_data\" # Path where the sound events, utterances and timelines database will be saved\n",
    "os.makedirs(DATA_PATH, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "dsc = scaper.Dscaper(dscaper_base_path=DATA_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/yanislabrak/opt/miniconda3/envs/jsalt/lib/python3.9/site-packages/torch/nn/modules/rnn.py:83: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.2 and num_layers=1\n",
      "  warnings.warn(\"dropout option adds dropout after all but last \"\n",
      "/Users/yanislabrak/opt/miniconda3/envs/jsalt/lib/python3.9/site-packages/torch/nn/utils/weight_norm.py:28: UserWarning: torch.nn.utils.weight_norm is deprecated in favor of torch.nn.utils.parametrizations.weight_norm.\n",
      "  warnings.warn(\"torch.nn.utils.weight_norm is deprecated in favor of torch.nn.utils.parametrizations.weight_norm.\")\n"
     ]
    }
   ],
   "source": [
    "audio_pipeline = AudioPipeline(dscaper=dsc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Populating dSCAPER with sdialog/background dataset...:   0%|          | 0/4 [00:00<?, ?it/s][2025-09-27 20:47:31] ERROR:root:Problem storing audio /Users/yanislabrak/.cache/huggingface/hub/datasets--sdialog--background/snapshots/899f03337bf907855fa99ececdadbcabf3705ab6/ac_noise/351790__reiyamanor__small-room-tone-vintage-air-condition-at.wav (the audio can also be already stored)\n",
      "Populating dSCAPER with sdialog/background dataset...:  25%|██▌       | 1/4 [00:01<00:03,  1.12s/it][2025-09-27 20:47:31] ERROR:root:Problem storing audio /Users/yanislabrak/.cache/huggingface/hub/datasets--sdialog--background/snapshots/899f03337bf907855fa99ececdadbcabf3705ab6/ac_noise/546572__tim_verberne__f_st_room_tone_04.wav (the audio can also be already stored)\n",
      "[2025-09-27 20:47:31] ERROR:root:Problem storing audio /Users/yanislabrak/.cache/huggingface/hub/datasets--sdialog--background/snapshots/899f03337bf907855fa99ececdadbcabf3705ab6/fan_noise/210098__yuval__room-big-fan.wav (the audio can also be already stored)\n",
      "Populating dSCAPER with sdialog/background dataset...:  75%|███████▌  | 3/4 [00:01<00:00,  2.97it/s][2025-09-27 20:47:31] ERROR:root:Problem storing audio /Users/yanislabrak/.cache/huggingface/hub/datasets--sdialog--background/snapshots/899f03337bf907855fa99ececdadbcabf3705ab6/fan_noise/674563__klankbeeld__room-tone-fan-801am-220813_0497.wav (the audio can also be already stored)\n",
      "Populating dSCAPER with sdialog/background dataset...: 100%|██████████| 4/4 [00:01<00:00,  2.97it/s]\n",
      "Populating dSCAPER with sdialog/foreground dataset...:   0%|          | 0/8 [00:00<?, ?it/s][2025-09-27 20:47:33] ERROR:root:Problem storing audio /Users/yanislabrak/.cache/huggingface/hub/datasets--sdialog--foreground/snapshots/d3249cd6ec624a5fb525ae5a41e97cc9770b36ef/chair_sitting_down/249570__rivernile7__sitting-down-on-chair.wav (the audio can also be already stored)\n",
      "[2025-09-27 20:47:33] ERROR:root:Problem storing audio /Users/yanislabrak/.cache/huggingface/hub/datasets--sdialog--foreground/snapshots/d3249cd6ec624a5fb525ae5a41e97cc9770b36ef/keyboard_typing/331428__m4taiori__mechanical-keyboard-typing.mp3 (the audio can also be already stored)\n",
      "[2025-09-27 20:47:33] ERROR:root:Problem storing audio /Users/yanislabrak/.cache/huggingface/hub/datasets--sdialog--foreground/snapshots/d3249cd6ec624a5fb525ae5a41e97cc9770b36ef/keyboard_typing/332458__thegreatrazz__keyboard-typing.wav (the audio can also be already stored)\n",
      "[2025-09-27 20:47:33] ERROR:root:Problem storing audio /Users/yanislabrak/.cache/huggingface/hub/datasets--sdialog--foreground/snapshots/d3249cd6ec624a5fb525ae5a41e97cc9770b36ef/keyboard_typing/376960__director1406__keyboard-typing-fast.mp3 (the audio can also be already stored)\n",
      "Populating dSCAPER with sdialog/foreground dataset...:  50%|█████     | 4/8 [00:00<00:00, 31.70it/s][2025-09-27 20:47:33] ERROR:root:Problem storing audio /Users/yanislabrak/.cache/huggingface/hub/datasets--sdialog--foreground/snapshots/d3249cd6ec624a5fb525ae5a41e97cc9770b36ef/keyboard_typing/546166__grcekh__keyboard-typing-9-whitefox-mechanical.mp3 (the audio can also be already stored)\n",
      "[2025-09-27 20:47:33] ERROR:root:Problem storing audio /Users/yanislabrak/.cache/huggingface/hub/datasets--sdialog--foreground/snapshots/d3249cd6ec624a5fb525ae5a41e97cc9770b36ef/keyboard_typing/559892__sorinious_genious__keyboard-fast-typing-no-accents.wav (the audio can also be already stored)\n",
      "[2025-09-27 20:47:33] ERROR:root:Problem storing audio /Users/yanislabrak/.cache/huggingface/hub/datasets--sdialog--foreground/snapshots/d3249cd6ec624a5fb525ae5a41e97cc9770b36ef/keyboard_typing/665075__zrrion__keyboard-typing-sounds-unidentified-technics-keyboard.ogg (the audio can also be already stored)\n",
      "[2025-09-27 20:47:33] ERROR:root:Problem storing audio /Users/yanislabrak/.cache/huggingface/hub/datasets--sdialog--foreground/snapshots/d3249cd6ec624a5fb525ae5a41e97cc9770b36ef/white_noise/37612__soundstack__white-noise-impulse.wav (the audio can also be already stored)\n",
      "Populating dSCAPER with sdialog/foreground dataset...: 100%|██████████| 8/8 [00:00<00:00, 19.87it/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Populate the sound events database\n",
    "audio_pipeline.populate_dscaper([\"sdialog/background\",\"sdialog/foreground\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2025-09-27 20:47:33] ERROR:root:Problem storing audio for turn ./outputs/dialog_1752861530588/utterances/0_DOCTOR.wav\n",
      "[2025-09-27 20:47:33] ERROR:root:Problem storing audio for turn ./outputs/dialog_1752861530588/utterances/1_PATIENT.wav\n",
      "[2025-09-27 20:47:33] ERROR:root:Problem storing audio for turn ./outputs/dialog_1752861530588/utterances/2_DOCTOR.wav\n",
      "[2025-09-27 20:47:33] ERROR:root:Problem storing audio for turn ./outputs/dialog_1752861530588/utterances/3_PATIENT.wav\n",
      "/Users/yanislabrak/Desktop/HUB/JSALT/sdialog/dscaper/scaper/core.py:1739: ScaperWarning: ac_noise source time tuple (const, 0.0) could not be satisfied given source duration (30.00) and event duration (45.15), source time tuple changed to (const, 0) but was still not satisfiable, likely due to using 'normal' distribution with bounds too close to the start or end of the audio file\n",
      "  warnings.warn(\n",
      "/Users/yanislabrak/Desktop/HUB/JSALT/sdialog/dscaper/scaper/core.py:1657: ScaperWarning: PATIENT event duration (11.20) is greater that source duration (10.82), changing to 10.82\n",
      "  warnings.warn(\n",
      "/Users/yanislabrak/Desktop/HUB/JSALT/sdialog/dscaper/scaper/core.py:1657: ScaperWarning: DOCTOR event duration (12.10) is greater that source duration (12.05), changing to 12.05\n",
      "  warnings.warn(\n",
      "/Users/yanislabrak/Desktop/HUB/JSALT/sdialog/dscaper/scaper/core.py:1657: ScaperWarning: PATIENT event duration (16.80) is greater that source duration (16.77), changing to 16.77\n",
      "  warnings.warn(\n",
      "/Users/yanislabrak/Desktop/HUB/JSALT/sdialog/dscaper/scaper/core.py:1769: ScaperWarning: PATIENT event time (28.40) is too great given event duration (16.77) and soundscape duration (45.15), changed to 28.38.\n",
      "  warnings.warn(\n",
      "/Users/yanislabrak/Desktop/HUB/JSALT/sdialog/dscaper/scaper/core.py:1657: ScaperWarning: white_noise event duration (0.10) is greater that source duration (0.02), changing to 0.02\n",
      "  warnings.warn(\n",
      "/Users/yanislabrak/Desktop/HUB/JSALT/sdialog/dscaper/scaper/core.py:1657: ScaperWarning: PATIENT event duration (18.40) is greater that source duration (16.77), changing to 16.77\n",
      "  warnings.warn(\n",
      "/Users/yanislabrak/Desktop/HUB/JSALT/sdialog/dscaper/scaper/core.py:1657: ScaperWarning: PATIENT event duration (11.40) is greater that source duration (10.82), changing to 10.82\n",
      "  warnings.warn(\n",
      "/Users/yanislabrak/Desktop/HUB/JSALT/sdialog/dscaper/scaper/core.py:1657: ScaperWarning: PATIENT event duration (17.60) is greater that source duration (16.77), changing to 16.77\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "./outputs/dialog_1752861530588/exported_audios/audio_pipeline_step1.wav\n",
      "Loading utterances and combined audio from dialogue 1752861530588\n",
      "Audio data from step 1 loaded into the dialog (1752861530588) successfully!\n",
      "Sending utterances to dSCAPER for dialogue 1752861530588\n",
      "Generating timeline from dSCAPER for dialogue 1752861530588\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/yanislabrak/Desktop/HUB/JSALT/sdialog/dscaper/scaper/core.py:2286: ScaperWarning: Soundscape audio is clipping!\n",
      "  warnings.warn('Soundscape audio is clipping!',\n",
      "/Users/yanislabrak/opt/miniconda3/envs/jsalt/lib/python3.9/site-packages/soxbindings/effects.py:93: RuntimeWarning: invalid value encountered in cast\n",
      "  input_data = input_data.astype(np.int32)\n",
      "/Users/yanislabrak/Desktop/HUB/JSALT/sdialog/dscaper/scaper/core.py:2286: ScaperWarning: Soundscape audio is clipping!\n",
      "  warnings.warn('Soundscape audio is clipping!',\n",
      "/Users/yanislabrak/opt/miniconda3/envs/jsalt/lib/python3.9/site-packages/soxbindings/effects.py:93: RuntimeWarning: invalid value encountered in cast\n",
      "  input_data = input_data.astype(np.int32)\n",
      "/Users/yanislabrak/Desktop/HUB/JSALT/sdialog/dscaper/scaper/core.py:2286: ScaperWarning: Soundscape audio is clipping!\n",
      "  warnings.warn('Soundscape audio is clipping!',\n",
      "/Users/yanislabrak/opt/miniconda3/envs/jsalt/lib/python3.9/site-packages/soxbindings/effects.py:93: RuntimeWarning: invalid value encountered in cast\n",
      "  input_data = input_data.astype(np.int32)\n",
      "/Users/yanislabrak/Desktop/HUB/JSALT/sdialog/dscaper/scaper/core.py:2286: ScaperWarning: Soundscape audio is clipping!\n",
      "  warnings.warn('Soundscape audio is clipping!',\n",
      "/Users/yanislabrak/opt/miniconda3/envs/jsalt/lib/python3.9/site-packages/soxbindings/effects.py:93: RuntimeWarning: invalid value encountered in cast\n",
      "  input_data = input_data.astype(np.int32)\n",
      "[2025-09-27 20:47:40] INFO:root:Successfully generated dscaper timeline.\n",
      "[2025-09-27 20:47:40] WARNING:root:The room or the dSCAPER is not set, which make the generation of the room accoustic audio impossible\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Timeline generated from dSCAPER for dialogue 1752861530588\n",
      "./outputs/dialog_1752861530588/exported_audios/audio_pipeline_step1.wav\n",
      "./outputs/dialog_1752861530588/exported_audios/audio_pipeline_step2.wav\n"
     ]
    }
   ],
   "source": [
    "dialog: AudioDialog = audio_pipeline.inference(dialog)\n",
    "print(dialog.audio_step_1_filepath)\n",
    "print(dialog.audio_step_2_filepath)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 3 : Room Accoustics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/yanislabrak/opt/miniconda3/envs/jsalt/lib/python3.9/site-packages/torch/nn/modules/rnn.py:83: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.2 and num_layers=1\n",
      "  warnings.warn(\"dropout option adds dropout after all but last \"\n",
      "/Users/yanislabrak/opt/miniconda3/envs/jsalt/lib/python3.9/site-packages/torch/nn/utils/weight_norm.py:28: UserWarning: torch.nn.utils.weight_norm is deprecated in favor of torch.nn.utils.parametrizations.weight_norm.\n",
      "  warnings.warn(\"torch.nn.utils.weight_norm is deprecated in favor of torch.nn.utils.parametrizations.weight_norm.\")\n"
     ]
    }
   ],
   "source": [
    "audio_pipeline = AudioPipeline(dscaper=dsc) # The audio pipeline doesn't change"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sdialog.audio.room import MicrophonePosition\n",
    "from sdialog.audio.room_generator import RoomGenerator, RoomRole"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8863:  RoomRole.CONSULTATION room_8863, desc: consultation room (dimentions: dim: [3.577708763999664, 2.23606797749979, 3.0], rt60: 0.5) role: RoomRole.CONSULTATION)  \n"
     ]
    }
   ],
   "source": [
    "room = RoomGenerator().generate(RoomRole.CONSULTATION, room_size=8.0)\n",
    "print(room)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "./outputs/dialog_1752861530588/exported_audios/audio_pipeline_step1.wav\n",
      "Loading utterances and combined audio from dialogue 1752861530588\n",
      "Audio data from step 1 loaded into the dialog (1752861530588) successfully!\n",
      "./outputs/dialog_1752861530588/exported_audios/audio_pipeline_step1.wav\n",
      "./outputs/dialog_1752861530588/exported_audios/audio_pipeline_step2.wav\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "dialog: AudioDialog = audio_pipeline.inference(\n",
    "    dialog,\n",
    "    room=room, # Need to provide a room object to trigger the 3rd step of the audio pipeline\n",
    "    # microphone_position=MicrophonePosition.MONITOR # Default is MicrophonePosition.MONITOR\n",
    "    microphone_position=MicrophonePosition.CEILING_CENTERED, # Default is MicrophonePosition.MONITOR\n",
    "    do_step_1=True,\n",
    "    do_step_2=False,\n",
    "    do_step_3=False,\n",
    ")\n",
    "print(dialog.audio_step_1_filepath)\n",
    "print(dialog.audio_step_2_filepath)\n",
    "print(dialog.audio_step_3_filepath)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Custom dialog directory names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "./outputs/demo_dialog/exported_audios/audio_pipeline_step1.wav\n",
      "Generating utterances audios from dialogue 1752861530588\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating utterances audios:   0%|          | 0/4 [00:00<?, ?it/s][W NNPACK.cpp:64] Could not initialize NNPACK! Reason: Unsupported hardware.\n",
      "Generating utterances audios: 100%|██████████| 4/4 [00:20<00:00,  5.13s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "./outputs/demo_dialog/exported_audios/audio_pipeline_step1.wav\n",
      "./outputs/dialog_1752861530588/exported_audios/audio_pipeline_step2.wav\n",
      "None\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "dialog: AudioDialog = audio_pipeline.inference(\n",
    "    dialog,\n",
    "    room=room, # Need to provide a room object to trigger the 3rd step of the audio pipeline\n",
    "    # microphone_position=MicrophonePosition.MONITOR # Default is MicrophonePosition.MONITOR\n",
    "    microphone_position=MicrophonePosition.CEILING_CENTERED, # Default is MicrophonePosition.MONITOR\n",
    "    do_step_1=True,\n",
    "    do_step_2=False,\n",
    "    do_step_3=False,\n",
    "    dialog_dir_name=\"demo_dialog\"\n",
    ")\n",
    "print(dialog.audio_step_1_filepath)\n",
    "print(dialog.audio_step_2_filepath)\n",
    "print(dialog.audio_step_3_filepath)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "jsalt",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.23"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
