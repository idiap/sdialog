{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# On Jean Zay HPC"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```bash\n",
    "module purge\n",
    "\n",
    "module load arch/h100\n",
    "module load cuda/12.4.1\n",
    "module load ffmpeg/6.1.1\n",
    "\n",
    "module load miniforge\n",
    "\n",
    "conda activate jsalt10\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you want to perform dScaper and PyRoomAcoustics (steps 2 and 3):\n",
    "```bash\n",
    "cd ./dscaper\n",
    "pip install -e .\n",
    "\n",
    "conda install sox\n",
    "pip install sox\n",
    "\n",
    "pip install jams\n",
    "pip install pyloudnorm\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SDialog dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%script false --no-raise-error\n",
    "# Only run this cell if you are using a non jupyter environment\n",
    "!conda create --name jsalt python=3.9 -y\n",
    "!conda activate jsalt\n",
    "!conda install sox\n",
    "!pip install -r sdialog/requirements.txt\n",
    "!pip install -r sdialog/requirements-audio.txt\n",
    "#  conda activate jsalt-Py3-10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/yanislabrak/opt/miniconda3/envs/jsalt/lib/python3.9/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import sdialog\n",
    "from sdialog import Dialog\n",
    "from sdialog.generators import PersonaGenerator\n",
    "from sdialog.personas import Persona, PersonaAgent, Doctor, Patient, Agent"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generate Persona"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "sdialog.config.set_llm(\"aws:anthropic.claude-3-5-sonnet-20240620-v1:0\", region_name=\"us-east-1\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%script false --no-raise-error\n",
    "persona_card_folder = \"./personas\"\n",
    "\n",
    "# Generate doctor persona\n",
    "doctor_persona = Doctor(\n",
    "    name=\"Dr. Smith\",\n",
    "    gender=\"male\",\n",
    "    age=52,\n",
    "    specialty=\"Family Medicine\"\n",
    ")\n",
    "generator_doctor = PersonaGenerator(doctor_persona)\n",
    "persona_cards = generator_doctor.generate(n=1)\n",
    "persona_cards.to_file(f\"{persona_card_folder}/persona_doctor.json\")\n",
    "\n",
    "# Generate patient persona\n",
    "patient_persona = Patient(\n",
    "    name=\"John Doe\",\n",
    "    gender=\"male\",\n",
    "    age=62\n",
    ")\n",
    "generator_patient = PersonaGenerator(patient_persona)\n",
    "persona_cards = generator_patient.generate(n=1)\n",
    "persona_cards.to_file(f\"{persona_card_folder}/persona_patient.json\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load persona"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load personas\n",
    "persona_doctor = Persona.from_file(\"./personas/persona_doctor.json\")\n",
    "persona_patient = Persona.from_file(\"./personas/persona_patient.json\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%script false --no-raise-error\n",
    "context = \"Generate me a 50 turn medical dialogue between patient and doctor, for a primary care visit\"\n",
    "\n",
    "# Create agents\n",
    "agent1 = PersonaAgent(persona=persona_doctor, name=\"DOCTOR\", dialogue_details=context, response_details=\"make short turn answers when needed\")\n",
    "agent2 = PersonaAgent(persona=persona_patient, name=\"PATIENT\", dialogue_details=context, response_details=\"make short turn answers when needed\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_all = True\n",
    "GENERATE_PERSONA = True\n",
    "FORCE_DIALOG_GENERATION = False\n",
    "\n",
    "os.makedirs(\"./outputs\", exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m\u001b[95m[dialog_id] \u001b[35m1752861530588\u001b[0m\n",
      "\u001b[1m\u001b[95m[model] \u001b[35mclient=<botocore.client.BedrockRuntime object at 0x7fc319ec91c0> model_id='anthropic.claude-3-5-sonnet-20240620-v1:0' region_name='us-east-1' provider='anthropic' supports_tool_choice_values=('auto', 'any', 'tool')\u001b[0m\n",
      "\u001b[1m\u001b[95m[seed] \u001b[35m226296126\u001b[0m\n",
      "\u001b[1m\u001b[35m--- Dialogue Begins ---\u001b[0m\n",
      "\u001b[31m[DOCTOR] \u001b[0mHello there. I'm Dr. Smith. Welcome to my office. What brings you in to see me today?\u001b[0m\n",
      "\u001b[94m[PATIENT] \u001b[37mGood morning, Dr. Smith. I'm John Doe. I've been dealing with a persistent cough and feeling pretty tired for about three weeks now. It's starting to wear me down, and I thought I should get it checked out.\u001b[0m\n",
      "\u001b[31m[DOCTOR] \u001b[0mI'm sorry to hear you've been feeling unwell, Mr. Doe. A persistent cough and fatigue can certainly be troublesome. Let's get some more details. Can you describe your cough? Is it dry or productive?\u001b[0m\n",
      "\u001b[94m[PATIENT] \u001b[37mWell, Dr. Smith, it's mostly a dry cough. It's particularly bothersome at night when I'm trying to sleep. You know, it reminds me of the time I was teaching about the Civil War and how soldiers often suffered from \"camp cough\" due to poor conditions. Of course, I doubt my situation is that dire, but it's certainly annoying.\u001b[0m\n",
      "\u001b[1m\u001b[35m--- Dialogue Ends ---\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "if FORCE_DIALOG_GENERATION:\n",
    "\n",
    "    original_dialog = agent1.talk_with(agent2, max_turns=3)\n",
    "    original_dialog.to_file(\"dialog_demo.json\")\n",
    "\n",
    "else:\n",
    "    original_dialog = Dialog.from_file(\"dialog_demo.json\")\n",
    "\n",
    "original_dialog.print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Audio Generation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can generate three type of audios:\n",
    "- (default) Step 1: Raw utterances passed to a TTS model and concatenated to each others to create an audio file\n",
    "- Step 2: Audio generated from multiple channels create using signal positions\n",
    "- Step 3: Audio generated using room spacialization and multi-channels positions\n",
    "\n",
    "If you want to trigger the \"step 2\" you need to give a Scaper argument to the `audio_pipeline`. While for the \"step 3\" you need also to give a \"Room\" in the `inference` function."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Instanciate voices database"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'identifier': 'am_adam', 'voice': 'am_adam'}"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sdialog.audio.voice_database import DummyKokoroVoiceDatabase\n",
    "dummy_voice_database = DummyKokoroVoiceDatabase()\n",
    "dummy_voice_database.get_voice(genre=\"male\", age=20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "OR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%script false --no-raise-error\n",
    "from sdialog.audio.voice_database import HuggingfaceVoiceDatabase\n",
    "voices_libritts = HuggingfaceVoiceDatabase(\"sdialog/voices-libritts\")\n",
    "voices_libritts.get_voice(genre=\"male\", age=20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "OR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%script false --no-raise-error\n",
    "from sdialog.audio.voice_database import HuggingfaceVoiceDatabase\n",
    "dummy_voice_database = HuggingfaceVoiceDatabase(\"sdialog/voices-jsalt\")\n",
    "dummy_voice_database.get_voice(genre=\"male\", age=20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Instanciate TTS model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/yanislabrak/opt/miniconda3/envs/jsalt/lib/python3.9/site-packages/torch/nn/modules/rnn.py:83: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.2 and num_layers=1\n",
      "  warnings.warn(\"dropout option adds dropout after all but last \"\n",
      "/Users/yanislabrak/opt/miniconda3/envs/jsalt/lib/python3.9/site-packages/torch/nn/utils/weight_norm.py:28: UserWarning: torch.nn.utils.weight_norm is deprecated in favor of torch.nn.utils.parametrizations.weight_norm.\n",
      "  warnings.warn(\"torch.nn.utils.weight_norm is deprecated in favor of torch.nn.utils.parametrizations.weight_norm.\")\n"
     ]
    }
   ],
   "source": [
    "from sdialog.audio.tts_engine import KokoroTTS\n",
    "tts_pipeline = KokoroTTS()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%script false --no-raise-error\n",
    "##################################################\n",
    "# DOESN'T WORK ON MULTILINGUAL MACOS\n",
    "##################################################\n",
    "\n",
    "# Generate multilingual audio from text using the Kokoro model\n",
    "\n",
    "from sdialog.audio.tts_engine import KokoroTTS\n",
    "\n",
    "tts_pipeline = KokoroTTS(lang_code=\"f\")\n",
    "# tts_pipeline = KokoroTTS(lang_code=\"a\")\n",
    "\n",
    "from phonemizer.backend.espeak.wrapper import EspeakWrapper\n",
    "_ESPEAK_LIBRARY = '/opt/homebrew/Cellar/espeak/1.48.04_1/lib/libespeak.1.1.48.dylib'\n",
    "EspeakWrapper.set_library(_ESPEAK_LIBRARY)\n",
    "\n",
    "import soundfile\n",
    "audio, sampling_rate = tts_pipeline.generate(\n",
    "    # \"Hi, how are you today?\",\n",
    "    # \"af_alloy\"\n",
    "    \"Bonjour, comment ça va?\",\n",
    "    \"ff_siwis\"\n",
    ")\n",
    "print(audio)\n",
    "print(sampling_rate)\n",
    "output_file_name = \"./test_index_tts_french.wav\"\n",
    "soundfile.write(output_file_name, audio, sampling_rate)\n",
    "print(f\"Audio saved to {output_file_name}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "OR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%script false --no-raise-error\n",
    "from sdialog.audio.tts_engine import IndexTTS\n",
    "tts_pipeline = IndexTTS(device=\"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%script false --no-raise-error\n",
    "# Generate audio from text using the IndexTTS model\n",
    "import soundfile\n",
    "audio, sampling_rate = tts_pipeline.generate(\n",
    "    \"Brno is the best city in the planet, you know? and Loco Polaco is the craziest person I know\",\n",
    "    \"./sergio.wav\"\n",
    ")\n",
    "soundfile.write(\"./test_index_tts.wav\", audio, sampling_rate)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup stage: Audio Dialog and Audio Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sdialog.audio.audio_dialog import AudioDialog\n",
    "from sdialog.audio.audio_pipeline import AudioPipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "dialog: AudioDialog = AudioDialog.from_dialog(original_dialog)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 1 : Concatenated utterances"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "audio_pipeline = AudioPipeline(\n",
    "    voice_database=dummy_voice_database,\n",
    "    tts_pipeline=tts_pipeline,\n",
    "    dir_audio=\"./outputs\",\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "OR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%script false --no-raise-error\n",
    "audio_pipeline = AudioPipeline() # Default values are used"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2025-09-28 13:27:13] INFO:root:Dialog audio dir path: ./outputs\n",
      "[2025-09-28 13:27:13] INFO:root:Generating utterances audios from dialogue 1752861530588\n",
      "Generating utterances audios:   0%|          | 0/4 [00:00<?, ?it/s][W NNPACK.cpp:64] Could not initialize NNPACK! Reason: Unsupported hardware.\n",
      "Generating utterances audios: 100%|██████████| 4/4 [00:25<00:00,  6.25s/it]\n",
      "[2025-09-28 13:27:38] WARNING:root:The dSCAPER is not set, which make the generation of the timeline impossible\n",
      "[2025-09-28 13:27:38] WARNING:root:The room or the dSCAPER is not set, which make the generation of the room accoustic audio impossible\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "./outputs/dialog_1752861530588/exported_audios/audio_pipeline_step1.wav\n"
     ]
    }
   ],
   "source": [
    "dialog: AudioDialog = audio_pipeline.inference(dialog) # Generate the audio for the dialog\n",
    "print(dialog.audio_step_1_filepath) # Path to the audio of the first stage of the audio pipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 2: dScaper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%script false --no-raise-error\n",
    "!git clone https://github.com/cyrta/dscaper.git"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%script false --no-raise-error\n",
    "%pip install -r ../../../requirements-dscaper.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "import scaper\n",
    "DATA_PATH = \"./dscaper_data\" # Path where the sound events, utterances and timelines database will be saved\n",
    "os.makedirs(DATA_PATH, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "dsc = scaper.Dscaper(dscaper_base_path=DATA_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/yanislabrak/opt/miniconda3/envs/jsalt/lib/python3.9/site-packages/torch/nn/modules/rnn.py:83: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.2 and num_layers=1\n",
      "  warnings.warn(\"dropout option adds dropout after all but last \"\n",
      "/Users/yanislabrak/opt/miniconda3/envs/jsalt/lib/python3.9/site-packages/torch/nn/utils/weight_norm.py:28: UserWarning: torch.nn.utils.weight_norm is deprecated in favor of torch.nn.utils.parametrizations.weight_norm.\n",
      "  warnings.warn(\"torch.nn.utils.weight_norm is deprecated in favor of torch.nn.utils.parametrizations.weight_norm.\")\n"
     ]
    }
   ],
   "source": [
    "audio_pipeline = AudioPipeline(dscaper=dsc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Populating dSCAPER with sdialog/background dataset...: 100%|██████████| 4/4 [00:01<00:00,  2.50it/s]\n",
      "Populating dSCAPER with sdialog/foreground dataset...: 100%|██████████| 8/8 [00:00<00:00, 20.17it/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'count_existing_audio_files': 0,\n",
       " 'count_error_audio_files': 0,\n",
       " 'count_success_audio_files': 12}"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Populate the sound events database\n",
    "audio_pipeline.populate_dscaper([\"sdialog/background\",\"sdialog/foreground\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2025-09-28 13:27:48] INFO:root:Dialog audio dir path: ./outputs\n",
      "[2025-09-28 13:27:48] INFO:root:Audio data from step 1 loaded into the dialog (1752861530588) successfully!\n",
      "[2025-09-28 13:27:48] INFO:root:==============================\n",
      "[2025-09-28 13:27:48] INFO:root:# Audio sent to dSCAPER\n",
      "[2025-09-28 13:27:48] INFO:root:==============================\n",
      "[2025-09-28 13:27:48] INFO:root:Already present: 0\n",
      "[2025-09-28 13:27:48] INFO:root:Correctly added: 4\n",
      "[2025-09-28 13:27:48] INFO:root:Errors: 0\n",
      "[2025-09-28 13:27:48] INFO:root:==============================\n",
      "[2025-09-28 13:27:48] INFO:root:Generating timeline from dSCAPER for dialogue 1752861530588\n",
      "/Users/yanislabrak/Desktop/HUB/JSALT/sdialog/dscaper/scaper/core.py:1657: ScaperWarning: white_noise event duration (0.10) is greater that source duration (0.02), changing to 0.02\n",
      "  warnings.warn(\n",
      "/Users/yanislabrak/Desktop/HUB/JSALT/sdialog/dscaper/scaper/core.py:2286: ScaperWarning: Soundscape audio is clipping!\n",
      "  warnings.warn('Soundscape audio is clipping!',\n",
      "/Users/yanislabrak/opt/miniconda3/envs/jsalt/lib/python3.9/site-packages/soxbindings/effects.py:93: RuntimeWarning: invalid value encountered in cast\n",
      "  input_data = input_data.astype(np.int32)\n",
      "/Users/yanislabrak/Desktop/HUB/JSALT/sdialog/dscaper/scaper/core.py:2286: ScaperWarning: Soundscape audio is clipping!\n",
      "  warnings.warn('Soundscape audio is clipping!',\n",
      "/Users/yanislabrak/opt/miniconda3/envs/jsalt/lib/python3.9/site-packages/soxbindings/effects.py:93: RuntimeWarning: invalid value encountered in cast\n",
      "  input_data = input_data.astype(np.int32)\n",
      "[2025-09-28 13:27:50] INFO:root:Successfully generated dscaper timeline.\n",
      "[2025-09-28 13:27:50] INFO:root:Timeline generated from dSCAPER for dialogue 1752861530588\n",
      "[2025-09-28 13:27:50] WARNING:root:The room or the dSCAPER is not set, which make the generation of the room accoustic audio impossible\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "./outputs/dialog_1752861530588/exported_audios/audio_pipeline_step1.wav\n",
      "./outputs/dialog_1752861530588/exported_audios/audio_pipeline_step2.wav\n"
     ]
    }
   ],
   "source": [
    "dialog: AudioDialog = audio_pipeline.inference(dialog)\n",
    "print(dialog.audio_step_1_filepath)\n",
    "print(dialog.audio_step_2_filepath)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 3 : Room Accoustics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/yanislabrak/opt/miniconda3/envs/jsalt/lib/python3.9/site-packages/torch/nn/modules/rnn.py:83: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.2 and num_layers=1\n",
      "  warnings.warn(\"dropout option adds dropout after all but last \"\n",
      "/Users/yanislabrak/opt/miniconda3/envs/jsalt/lib/python3.9/site-packages/torch/nn/utils/weight_norm.py:28: UserWarning: torch.nn.utils.weight_norm is deprecated in favor of torch.nn.utils.parametrizations.weight_norm.\n",
      "  warnings.warn(\"torch.nn.utils.weight_norm is deprecated in favor of torch.nn.utils.parametrizations.weight_norm.\")\n"
     ]
    }
   ],
   "source": [
    "audio_pipeline = AudioPipeline(dscaper=dsc) # The audio pipeline doesn't change"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sdialog.audio.room import MicrophonePosition\n",
    "from sdialog.audio.room_generator import RoomGenerator, RoomRole"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8873:  consultation_room_8873, desc: consultation room (dimentions: dim: [3.577708763999664, 2.23606797749979, 3.0], rt60: 0.5) role: RoomRole.CONSULTATION)  \n",
      "--------------------------------\n",
      "consultation_room_8873\n"
     ]
    }
   ],
   "source": [
    "room = RoomGenerator().generate(RoomRole.CONSULTATION, room_size=8.0)\n",
    "print(room)\n",
    "print(\"--------------------------------\")\n",
    "print(room.name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2025-09-28 13:27:53] INFO:root:Dialog audio dir path: ./outputs\n",
      "[2025-09-28 13:27:53] INFO:root:Audio data from step 1 loaded into the dialog (1752861530588) successfully!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "./outputs/dialog_1752861530588/exported_audios/audio_pipeline_step1.wav\n",
      "./outputs/dialog_1752861530588/exported_audios/audio_pipeline_step2.wav\n",
      "{}\n"
     ]
    }
   ],
   "source": [
    "dialog: AudioDialog = audio_pipeline.inference(\n",
    "    dialog,\n",
    "    room=room, # Need to provide a room object to trigger the 3rd step of the audio pipeline\n",
    "    # microphone_position=MicrophonePosition.MONITOR # Default is MicrophonePosition.MONITOR\n",
    "    microphone_position=MicrophonePosition.CEILING_CENTERED, # Default is MicrophonePosition.MONITOR\n",
    "    do_step_1=True,\n",
    "    do_step_2=False,\n",
    "    do_step_3=False,\n",
    ")\n",
    "print(dialog.audio_step_1_filepath)\n",
    "print(dialog.audio_step_2_filepath)\n",
    "print(dialog.audio_step_3_filepaths)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Custom dialog directory names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2025-09-28 13:27:53] INFO:root:Dialog audio dir path: ./outputs\n",
      "[2025-09-28 13:27:53] INFO:root:Generating utterances audios from dialogue 1752861530588\n",
      "Generating utterances audios: 100%|██████████| 4/4 [00:22<00:00,  5.73s/it]\n",
      "[2025-09-28 13:28:16] INFO:root:==============================\n",
      "[2025-09-28 13:28:16] INFO:root:# Audio sent to dSCAPER\n",
      "[2025-09-28 13:28:16] INFO:root:==============================\n",
      "[2025-09-28 13:28:16] INFO:root:Already present: 0\n",
      "[2025-09-28 13:28:16] INFO:root:Correctly added: 4\n",
      "[2025-09-28 13:28:16] INFO:root:Errors: 0\n",
      "[2025-09-28 13:28:16] INFO:root:==============================\n",
      "[2025-09-28 13:28:16] INFO:root:Generating timeline from dSCAPER for dialogue 1752861530588\n",
      "/Users/yanislabrak/Desktop/HUB/JSALT/sdialog/dscaper/scaper/core.py:1657: ScaperWarning: DOCTOR event duration (11.10) is greater that source duration (11.05), changing to 11.05\n",
      "  warnings.warn(\n",
      "/Users/yanislabrak/Desktop/HUB/JSALT/sdialog/dscaper/scaper/core.py:1657: ScaperWarning: white_noise event duration (0.10) is greater that source duration (0.02), changing to 0.02\n",
      "  warnings.warn(\n",
      "/Users/yanislabrak/Desktop/HUB/JSALT/sdialog/dscaper/scaper/core.py:1657: ScaperWarning: DOCTOR event duration (5.20) is greater that source duration (5.15), changing to 5.15\n",
      "  warnings.warn(\n",
      "/Users/yanislabrak/Desktop/HUB/JSALT/sdialog/dscaper/scaper/core.py:2286: ScaperWarning: Soundscape audio is clipping!\n",
      "  warnings.warn('Soundscape audio is clipping!',\n",
      "/Users/yanislabrak/opt/miniconda3/envs/jsalt/lib/python3.9/site-packages/soxbindings/effects.py:93: RuntimeWarning: invalid value encountered in cast\n",
      "  input_data = input_data.astype(np.int32)\n",
      "[2025-09-28 13:28:17] INFO:root:Successfully generated dscaper timeline.\n",
      "[2025-09-28 13:28:17] INFO:root:Timeline generated from dSCAPER for dialogue 1752861530588\n",
      "[2025-09-28 13:28:17] INFO:root:Generating room accoustic for dialogue 1752861530588\n",
      "[2025-09-28 13:28:17] INFO:root:  Microphone set to position [0.9944271909999159, 0.33541019662496846, 1.2]\n",
      "[2025-09-28 13:28:17] INFO:root:  Microphone set to position [1.788854381999832, 1.118033988749895, 2.9]\n",
      "[2025-09-28 13:28:17] INFO:root:✓ Loaded audio file './dscaper_data/timelines/dialog_1752861530588/generate/ba304f73-590b-471e-a9bc-8c0711d63c35/soundscape_positions/no_type.wav' for 'no_type' with 1918350 samples\n",
      "[2025-09-28 13:28:17] INFO:root:✓ Loaded audio file './dscaper_data/timelines/dialog_1752861530588/generate/ba304f73-590b-471e-a9bc-8c0711d63c35/soundscape_positions/doctor-at_desk_sitting.wav' for 'doctor-at_desk_sitting' with 1918350 samples\n",
      "[2025-09-28 13:28:17] INFO:root:✓ Loaded audio file './dscaper_data/timelines/dialog_1752861530588/generate/ba304f73-590b-471e-a9bc-8c0711d63c35/soundscape_positions/patient-next_to_desk_sitting.wav' for 'patient-next_to_desk_sitting' with 1918350 samples\n",
      "[2025-09-28 13:28:17] INFO:root:✓ Loaded audio file './dscaper_data/timelines/demo_dialog/generate/2b1a8a06-5662-4e53-a9f4-25a90a10d322/soundscape_positions/no_type.wav' for 'no_type' with 1986704 samples\n",
      "[2025-09-28 13:28:17] INFO:root:✓ Loaded audio file './dscaper_data/timelines/demo_dialog/generate/2b1a8a06-5662-4e53-a9f4-25a90a10d322/soundscape_positions/doctor-at_desk_sitting.wav' for 'doctor-at_desk_sitting' with 1986704 samples\n",
      "[2025-09-28 13:28:17] INFO:root:✓ Loaded audio file './dscaper_data/timelines/demo_dialog/generate/2b1a8a06-5662-4e53-a9f4-25a90a10d322/soundscape_positions/patient-next_to_desk_sitting.wav' for 'patient-next_to_desk_sitting' with 1986704 samples\n",
      "[2025-09-28 13:28:19] INFO:root:Room accoustic generated for dialogue 1752861530588!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "./outputs/demo_dialog/exported_audios/audio_pipeline_step1.wav\n",
      "./outputs/demo_dialog/exported_audios/audio_pipeline_step2.wav\n",
      "{'consultation_room_8873': {'audio_path': './outputs/demo_dialog/exported_audios/rooms/audio_pipeline_step3-consultation_room_8873.wav', 'microphone_position': <MicrophonePosition.CEILING_CENTERED: 'ceiling_centered'>, 'room_name': 'consultation_room_8873', 'room': Room()}}\n"
     ]
    }
   ],
   "source": [
    "dialog: AudioDialog = audio_pipeline.inference(\n",
    "    dialog,\n",
    "    room=room, # Need to provide a room object to trigger the 3rd step of the audio pipeline\n",
    "    # microphone_position=MicrophonePosition.MONITOR # Default is MicrophonePosition.MONITOR\n",
    "    microphone_position=MicrophonePosition.CEILING_CENTERED, # Default is MicrophonePosition.MONITOR\n",
    "    do_step_1=True,\n",
    "    do_step_2=True,\n",
    "    do_step_3=True,\n",
    "    dialog_dir_name=\"demo_dialog\"\n",
    ")\n",
    "print(dialog.audio_step_1_filepath)\n",
    "print(dialog.audio_step_2_filepath)\n",
    "print(dialog.audio_step_3_filepaths)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Custom room accoustic audio file name\n",
    "\n",
    "You can customize the name of the file in order to fit with the setup of the room, microphone position and so on."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2025-09-28 13:31:24] INFO:root:Dialog audio dir path: ./outputs\n",
      "[2025-09-28 13:31:24] INFO:root:Audio data from step 1 loaded into the dialog (1752861530588) successfully!\n",
      "[2025-09-28 13:31:24] INFO:root:==============================\n",
      "[2025-09-28 13:31:24] INFO:root:# Audio sent to dSCAPER\n",
      "[2025-09-28 13:31:24] INFO:root:==============================\n",
      "[2025-09-28 13:31:24] INFO:root:Already present: 4\n",
      "[2025-09-28 13:31:24] INFO:root:Correctly added: 0\n",
      "[2025-09-28 13:31:24] INFO:root:Errors: 0\n",
      "[2025-09-28 13:31:24] INFO:root:==============================\n",
      "[2025-09-28 13:31:24] INFO:root:Generating timeline from dSCAPER for dialogue 1752861530588\n",
      "/Users/yanislabrak/Desktop/HUB/JSALT/sdialog/dscaper/scaper/core.py:1739: ScaperWarning: ac_noise source time tuple (const, 0.0) could not be satisfied given source duration (30.00) and event duration (45.05), source time tuple changed to (const, 0) but was still not satisfiable, likely due to using 'normal' distribution with bounds too close to the start or end of the audio file\n",
      "  warnings.warn(\n",
      "/Users/yanislabrak/Desktop/HUB/JSALT/sdialog/dscaper/scaper/core.py:1657: ScaperWarning: DOCTOR event duration (11.10) is greater that source duration (11.05), changing to 11.05\n",
      "  warnings.warn(\n",
      "/Users/yanislabrak/Desktop/HUB/JSALT/sdialog/dscaper/scaper/core.py:1657: ScaperWarning: DOCTOR event duration (5.20) is greater that source duration (5.15), changing to 5.15\n",
      "  warnings.warn(\n",
      "/Users/yanislabrak/Desktop/HUB/JSALT/sdialog/dscaper/scaper/core.py:1657: ScaperWarning: white_noise event duration (0.10) is greater that source duration (0.02), changing to 0.02\n",
      "  warnings.warn(\n",
      "/Users/yanislabrak/Desktop/HUB/JSALT/sdialog/dscaper/scaper/core.py:2286: ScaperWarning: Soundscape audio is clipping!\n",
      "  warnings.warn('Soundscape audio is clipping!',\n",
      "/Users/yanislabrak/opt/miniconda3/envs/jsalt/lib/python3.9/site-packages/soxbindings/effects.py:93: RuntimeWarning: invalid value encountered in cast\n",
      "  input_data = input_data.astype(np.int32)\n",
      "/Users/yanislabrak/Desktop/HUB/JSALT/sdialog/dscaper/scaper/core.py:2286: ScaperWarning: Soundscape audio is clipping!\n",
      "  warnings.warn('Soundscape audio is clipping!',\n",
      "/Users/yanislabrak/opt/miniconda3/envs/jsalt/lib/python3.9/site-packages/soxbindings/effects.py:93: RuntimeWarning: invalid value encountered in cast\n",
      "  input_data = input_data.astype(np.int32)\n",
      "/Users/yanislabrak/Desktop/HUB/JSALT/sdialog/dscaper/scaper/core.py:2286: ScaperWarning: Soundscape audio is clipping!\n",
      "  warnings.warn('Soundscape audio is clipping!',\n",
      "/Users/yanislabrak/opt/miniconda3/envs/jsalt/lib/python3.9/site-packages/soxbindings/effects.py:93: RuntimeWarning: invalid value encountered in cast\n",
      "  input_data = input_data.astype(np.int32)\n",
      "/Users/yanislabrak/Desktop/HUB/JSALT/sdialog/dscaper/scaper/core.py:2286: ScaperWarning: Soundscape audio is clipping!\n",
      "  warnings.warn('Soundscape audio is clipping!',\n",
      "/Users/yanislabrak/opt/miniconda3/envs/jsalt/lib/python3.9/site-packages/soxbindings/effects.py:93: RuntimeWarning: invalid value encountered in cast\n",
      "  input_data = input_data.astype(np.int32)\n",
      "[2025-09-28 13:31:28] INFO:root:Successfully generated dscaper timeline.\n",
      "[2025-09-28 13:31:28] INFO:root:Timeline generated from dSCAPER for dialogue 1752861530588\n",
      "[2025-09-28 13:31:28] INFO:root:Generating room accoustic for dialogue 1752861530588\n",
      "[2025-09-28 13:31:28] INFO:root:  Microphone set to position [0.9944271909999159, 0.33541019662496846, 1.2]\n",
      "[2025-09-28 13:31:28] INFO:root:  Microphone set to position [1.788854381999832, 1.118033988749895, 2.9]\n",
      "[2025-09-28 13:31:28] INFO:root:✓ Loaded audio file './dscaper_data/timelines/dialog_1752861530588/generate/ba304f73-590b-471e-a9bc-8c0711d63c35/soundscape_positions/no_type.wav' for 'no_type' with 1918350 samples\n",
      "[2025-09-28 13:31:28] INFO:root:✓ Loaded audio file './dscaper_data/timelines/dialog_1752861530588/generate/ba304f73-590b-471e-a9bc-8c0711d63c35/soundscape_positions/doctor-at_desk_sitting.wav' for 'doctor-at_desk_sitting' with 1918350 samples\n",
      "[2025-09-28 13:31:28] INFO:root:✓ Loaded audio file './dscaper_data/timelines/dialog_1752861530588/generate/ba304f73-590b-471e-a9bc-8c0711d63c35/soundscape_positions/patient-next_to_desk_sitting.wav' for 'patient-next_to_desk_sitting' with 1918350 samples\n",
      "[2025-09-28 13:31:28] INFO:root:✓ Loaded audio file './dscaper_data/timelines/demo_dialog/generate/2b1a8a06-5662-4e53-a9f4-25a90a10d322/soundscape_positions/no_type.wav' for 'no_type' with 1986704 samples\n",
      "[2025-09-28 13:31:28] INFO:root:✓ Loaded audio file './dscaper_data/timelines/demo_dialog/generate/2b1a8a06-5662-4e53-a9f4-25a90a10d322/soundscape_positions/doctor-at_desk_sitting.wav' for 'doctor-at_desk_sitting' with 1986704 samples\n",
      "[2025-09-28 13:31:28] INFO:root:✓ Loaded audio file './dscaper_data/timelines/demo_dialog/generate/2b1a8a06-5662-4e53-a9f4-25a90a10d322/soundscape_positions/patient-next_to_desk_sitting.wav' for 'patient-next_to_desk_sitting' with 1986704 samples\n",
      "[2025-09-28 13:31:28] INFO:root:✓ Loaded audio file './dscaper_data/timelines/demo_dialog/generate/0ba65a04-207f-4cc0-808f-a6f153a80fd3/soundscape_positions/no_type.wav' for 'no_type' with 1986704 samples\n",
      "[2025-09-28 13:31:28] INFO:root:✓ Loaded audio file './dscaper_data/timelines/demo_dialog/generate/0ba65a04-207f-4cc0-808f-a6f153a80fd3/soundscape_positions/doctor-at_desk_sitting.wav' for 'doctor-at_desk_sitting' with 1986704 samples\n",
      "[2025-09-28 13:31:28] INFO:root:✓ Loaded audio file './dscaper_data/timelines/demo_dialog/generate/0ba65a04-207f-4cc0-808f-a6f153a80fd3/soundscape_positions/patient-next_to_desk_sitting.wav' for 'patient-next_to_desk_sitting' with 1986704 samples\n",
      "[2025-09-28 13:31:28] INFO:root:✓ Loaded audio file './dscaper_data/timelines/demo_dialog/generate/9a35272b-ab31-4920-9157-b1642198e541/soundscape_positions/no_type.wav' for 'no_type' with 1986704 samples\n",
      "[2025-09-28 13:31:28] INFO:root:✓ Loaded audio file './dscaper_data/timelines/demo_dialog/generate/9a35272b-ab31-4920-9157-b1642198e541/soundscape_positions/doctor-at_desk_sitting.wav' for 'doctor-at_desk_sitting' with 1986704 samples\n",
      "[2025-09-28 13:31:28] INFO:root:✓ Loaded audio file './dscaper_data/timelines/demo_dialog/generate/9a35272b-ab31-4920-9157-b1642198e541/soundscape_positions/patient-next_to_desk_sitting.wav' for 'patient-next_to_desk_sitting' with 1986704 samples\n",
      "[2025-09-28 13:31:32] WARNING:root:Room 'my_room_acc_1' already exists in the dialog\n",
      "[2025-09-28 13:31:32] INFO:root:Room accoustic generated for dialogue 1752861530588!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "./outputs/demo_dialog/exported_audios/audio_pipeline_step1.wav\n",
      "./outputs/demo_dialog/exported_audios/audio_pipeline_step2.wav\n",
      "{'consultation_room_8873': {'audio_path': './outputs/demo_dialog/exported_audios/rooms/audio_pipeline_step3-consultation_room_8873.wav', 'microphone_position': <MicrophonePosition.CEILING_CENTERED: 'ceiling_centered'>, 'room_name': 'consultation_room_8873', 'room': Room()}, 'my_room_acc_1': {'audio_path': './outputs/demo_dialog/exported_audios/rooms/audio_pipeline_step3-my_room_acc_1.wav', 'microphone_position': <MicrophonePosition.CEILING_CENTERED: 'ceiling_centered'>, 'room_name': 'my_room_acc_1', 'room': Room()}}\n"
     ]
    }
   ],
   "source": [
    "dialog: AudioDialog = audio_pipeline.inference(\n",
    "    dialog,\n",
    "    room=room, # Need to provide a room object to trigger the 3rd step of the audio pipeline\n",
    "    # microphone_position=MicrophonePosition.MONITOR # Default is MicrophonePosition.MONITOR\n",
    "    microphone_position=MicrophonePosition.CEILING_CENTERED, # Default is MicrophonePosition.MONITOR\n",
    "    do_step_1=True,\n",
    "    do_step_2=True,\n",
    "    do_step_3=True,\n",
    "    dialog_dir_name=\"demo_dialog\",\n",
    "    room_name=\"my_room_acc_1\"\n",
    ")\n",
    "print(dialog.audio_step_1_filepath)\n",
    "print(dialog.audio_step_2_filepath)\n",
    "print(dialog.audio_step_3_filepaths)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "jsalt",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.23"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
