{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SDialog dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%script false --no-raise-error\n",
    "# Only run this cell if you are using a non jupyter environment\n",
    "!conda create --name jsalt python=3.9 -y\n",
    "!conda activate jsalt\n",
    "!conda install sox\n",
    "!pip install -r sdialog/requirements.txt\n",
    "!pip install -r sdialog/requirements-audio.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/yanislabrak/opt/miniconda3/envs/jsalt-Py3-10/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import sdialog\n",
    "from sdialog import Dialog\n",
    "from sdialog.generators import PersonaGenerator\n",
    "from sdialog.personas import Persona, PersonaAgent, Doctor, Patient, Agent"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generate Persona"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "sdialog.config.set_llm(\"aws:anthropic.claude-3-5-sonnet-20240620-v1:0\", region_name=\"us-east-1\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%script false --no-raise-error\n",
    "persona_card_folder = \"./personas\"\n",
    "\n",
    "# Generate doctor persona\n",
    "doctor_persona = Doctor(\n",
    "    name=\"Dr. Smith\",\n",
    "    gender=\"male\",\n",
    "    age=52,\n",
    "    specialty=\"Family Medicine\"\n",
    ")\n",
    "generator_doctor = PersonaGenerator(doctor_persona)\n",
    "persona_cards = generator_doctor.generate(n=1)\n",
    "persona_cards.to_file(f\"{persona_card_folder}/persona_doctor.json\")\n",
    "\n",
    "# Generate patient persona\n",
    "patient_persona = Patient(\n",
    "    name=\"John Doe\",\n",
    "    gender=\"male\",\n",
    "    age=62\n",
    ")\n",
    "generator_patient = PersonaGenerator(patient_persona)\n",
    "persona_cards = generator_patient.generate(n=1)\n",
    "persona_cards.to_file(f\"{persona_card_folder}/persona_patient.json\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load persona"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load personas\n",
    "persona_doctor = Persona.from_file(\"./personas/persona_doctor.json\")\n",
    "persona_patient = Persona.from_file(\"./personas/persona_patient.json\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%script false --no-raise-error\n",
    "context = \"Generate me a 50 turn medical dialogue between patient and doctor, for a primary care visit\"\n",
    "\n",
    "# Create agents\n",
    "agent1 = PersonaAgent(persona=persona_doctor, name=\"DOCTOR\", dialogue_details=context, response_details=\"make short turn answers when needed\")\n",
    "agent2 = PersonaAgent(persona=persona_patient, name=\"PATIENT\", dialogue_details=context, response_details=\"make short turn answers when needed\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_all = True\n",
    "GENERATE_PERSONA = True\n",
    "FORCE_DIALOG_GENERATION = False\n",
    "\n",
    "os.makedirs(\"./outputs\", exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m\u001b[95m[dialog_id] \u001b[35m1752861530588\u001b[0m\n",
      "\u001b[1m\u001b[95m[model] \u001b[35mclient=<botocore.client.BedrockRuntime object at 0x7fc319ec91c0> model_id='anthropic.claude-3-5-sonnet-20240620-v1:0' region_name='us-east-1' provider='anthropic' supports_tool_choice_values=('auto', 'any', 'tool')\u001b[0m\n",
      "\u001b[1m\u001b[95m[seed] \u001b[35m226296126\u001b[0m\n",
      "\u001b[1m\u001b[35m--- Dialogue Begins ---\u001b[0m\n",
      "\u001b[31m[DOCTOR] \u001b[0mHello there. I'm Dr. Smith. Welcome to my office. What brings you in to see me today?\u001b[0m\n",
      "\u001b[94m[PATIENT] \u001b[37mGood morning, Dr. Smith. I'm John Doe. I've been dealing with a persistent cough and feeling pretty tired for about three weeks now. It's starting to wear me down, and I thought I should get it checked out.\u001b[0m\n",
      "\u001b[31m[DOCTOR] \u001b[0mI'm sorry to hear you've been feeling unwell, Mr. Doe. A persistent cough and fatigue can certainly be troublesome. Let's get some more details. Can you describe your cough? Is it dry or productive?\u001b[0m\n",
      "\u001b[94m[PATIENT] \u001b[37mWell, Dr. Smith, it's mostly a dry cough. It's particularly bothersome at night when I'm trying to sleep. You know, it reminds me of the time I was teaching about the Civil War and how soldiers often suffered from \"camp cough\" due to poor conditions. Of course, I doubt my situation is that dire, but it's certainly annoying.\u001b[0m\n",
      "\u001b[1m\u001b[35m--- Dialogue Ends ---\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "if FORCE_DIALOG_GENERATION:\n",
    "\n",
    "    original_dialog = agent1.talk_with(agent2, max_turns=3)\n",
    "    original_dialog.to_file(\"dialog_demo.json\")\n",
    "\n",
    "else:\n",
    "    original_dialog = Dialog.from_file(\"dialog_demo.json\")\n",
    "\n",
    "original_dialog.print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Audio Generation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can generate three type of audios:\n",
    "- (default) Step 1: Raw utterances passed to a TTS model and concatenated to each others to create an audio file\n",
    "- Step 2: Audio generated from multiple channels create using signal positions\n",
    "- Step 3: Audio generated using room spacialization and multi-channels positions\n",
    "\n",
    "If you want to trigger the \"step 2\" you need to give a Scaper argument to the `audio_pipeline`. While for the \"step 3\" you need also to give a \"Room\" in the `inference` function."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Instanciate voices database"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%script false --no-raise-error\n",
    "from sdialog.audio.voice_database import DummyVoiceDatabase\n",
    "dummy_voice_database = DummyVoiceDatabase()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "OR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%script false --no-raise-error\n",
    "from sdialog.audio.voice_database import HuggingfaceVoiceDatabase\n",
    "voices_libritts = HuggingfaceVoiceDatabase(\"sdialog/voices-libritts\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "OR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sdialog.audio.voice_database import HuggingfaceVoiceDatabase\n",
    "jsalt_voices = HuggingfaceVoiceDatabase(\"sdialog/voices-jsalt\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Instanciate TTS model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%script false --no-raise-error\n",
    "from sdialog.audio.tts_engine import KokoroTTS\n",
    "tts_pipeline = KokoroTTS()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "OR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">> GPT weights restored from: model/gpt.pth\n",
      "Removing weight norm...\n",
      ">> bigvgan weights restored from: model/bigvgan_generator.pth\n",
      ">> TextNormalizer loaded\n",
      ">> bpe model loaded from: model/bpe.model\n",
      ">> start inference...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[W NNPACK.cpp:64] Could not initialize NNPACK! Reason: Unsupported hardware.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">> Reference audio length: 13.89 seconds\n",
      ">> gpt_gen_time: 36.41 seconds\n",
      ">> gpt_forward_time: 2.87 seconds\n",
      ">> bigvgan_time: 9.29 seconds\n",
      ">> Total inference time: 48.72 seconds\n",
      ">> Generated audio length: 6.27 seconds\n",
      ">> RTF: 7.7674\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'soundfile' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[14], line 9\u001b[0m\n\u001b[1;32m      4\u001b[0m tts \u001b[38;5;241m=\u001b[39m IndexTTS()\n\u001b[1;32m      5\u001b[0m audio, sampling_rate \u001b[38;5;241m=\u001b[39m tts\u001b[38;5;241m.\u001b[39mgenerate(\n\u001b[1;32m      6\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mBrno is the best city in the planet, you know? and Loco Polaco is the craziest person I know\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m      7\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m./sergio.wav\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m      8\u001b[0m )\n\u001b[0;32m----> 9\u001b[0m \u001b[43msoundfile\u001b[49m\u001b[38;5;241m.\u001b[39mwrite(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m./test_index_tts.wav\u001b[39m\u001b[38;5;124m\"\u001b[39m, audio, sampling_rate)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'soundfile' is not defined"
     ]
    }
   ],
   "source": [
    "#  conda activate jsalt-Py3-10\n",
    "import torchaudio\n",
    "from sdialog.audio.tts_engine import IndexTTS\n",
    "tts = IndexTTS()\n",
    "audio, sampling_rate = tts.generate(\n",
    "    \"Brno is the best city in the planet, you know? and Loco Polaco is the craziest person I know\",\n",
    "    \"./sergio.wav\"\n",
    ")\n",
    "soundfile.write(\"./test_index_tts.wav\", audio, sampling_rate)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup stage: Audio Dialog and Audio Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sdialog.audio.audio_dialog import AudioDialog\n",
    "from sdialog.audio.audio_pipeline import AudioPipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dialog: AudioDialog = AudioDialog.from_dialog(original_dialog)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 1 : Concatenated utterances"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "audio_pipeline = AudioPipeline(\n",
    "    voice_database=dummy_voice_database,\n",
    "    tts_pipeline=tts_pipeline,\n",
    "    dir_audio=\"./outputs\",\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "OR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%script false --no-raise-error\n",
    "audio_pipeline = AudioPipeline() # Default values are used"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dialog: AudioDialog = audio_pipeline.inference(dialog) # Generate the audio for the dialog\n",
    "print(dialog.audio_step_1_filepath) # Path to the audio of the first stage of the audio pipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 2: dScaper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%script false --no-raise-error\n",
    "!git clone https://github.com/cyrta/dscaper.git"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%script false --no-raise-error\n",
    "%pip install -r ../../../requirements-dscaper.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import scaper\n",
    "DATA_PATH = \"./dscaper_data\" # Path where the sound events, utterances and timelines database will be saved\n",
    "os.makedirs(DATA_PATH, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dsc = scaper.Dscaper(dscaper_base_path=DATA_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "audio_pipeline = AudioPipeline(dscaper=dsc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Populate the sound events database\n",
    "audio_pipeline.populate_dscaper([\"sdialog/background\",\"sdialog/foreground\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dialog: AudioDialog = audio_pipeline.inference(dialog)\n",
    "print(dialog.audio_step_1_filepath)\n",
    "print(dialog.audio_step_2_filepath)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 3 : Room Accoustics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "audio_pipeline = AudioPipeline(dscaper=dsc) # The audio pipeline doesn't change"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sdialog.audio.room import MicrophonePosition\n",
    "from sdialog.audio.room_generator import RoomGenerator, RoomRole"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "room = RoomGenerator().generate(RoomRole.CONSULTATION)\n",
    "print(room)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dialog: AudioDialog = audio_pipeline.inference(\n",
    "    dialog,\n",
    "    room=room, # Need to provide a room object to trigger the 3rd step of the audio pipeline\n",
    "    # microphone_position=MicrophonePosition.MONITOR # Default is MicrophonePosition.CEILING_CENTERED\n",
    ")\n",
    "print(dialog.audio_step_1_filepath)\n",
    "print(dialog.audio_step_2_filepath)\n",
    "print(dialog.audio_step_3_filepath)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Automatic Position and SNR completion (under construction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sdialog.audio.audio_events_enricher import AudioEventsEnricher\n",
    "enricher = AudioEventsEnricher()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "audio_pipeline = AudioPipeline(enricher=enricher)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for turn in dialog.turns:\n",
    "    print(turn.text)\n",
    "    print(turn.position)\n",
    "    print(turn.snr)\n",
    "    print(\"____________________\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## dialog.to_audio()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Add a demo of the audio generation pipeline from the dialog object"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Audio Evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Utterance level evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sdialog.audio.evaluation import compute_evaluation_utterances, compute_evaluation_audio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Utterances level evaluation\n",
    "metrics_utterances_level = compute_evaluation_utterances(dialog)\n",
    "for key, value in metrics_utterances_level.items():\n",
    "    print(f\"{key}: {value}\")\n",
    "\n",
    "# Audio level evaluation\n",
    "metrics_audio_level = compute_evaluation_audio(dialog)\n",
    "for key, value in metrics_audio_level.items():\n",
    "    print(f\"{key}: {value}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Audio level evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Evaluate the final generated audio"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "jsalt-Py3-10",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
