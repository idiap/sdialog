{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SDialog dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%script false --no-raise-error\n",
    "# Only run this cell if you are using a non jupyter environment\n",
    "!conda create --name jsalt python=3.9 -y\n",
    "!conda activate jsalt\n",
    "!conda install sox\n",
    "!pip install -r sdialog/requirements.txt\n",
    "!pip install -r sdialog/requirements-audio.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/yanislabrak/opt/miniconda3/envs/jsalt/lib/python3.9/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import sdialog\n",
    "from sdialog import Dialog\n",
    "from sdialog.generators import PersonaGenerator\n",
    "from sdialog.personas import Persona, PersonaAgent, Doctor, Patient, Agent"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generate Persona"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "sdialog.config.set_llm(\"aws:anthropic.claude-3-5-sonnet-20240620-v1:0\", region_name=\"us-east-1\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%script false --no-raise-error\n",
    "persona_card_folder = \"./personas\"\n",
    "\n",
    "# Generate doctor persona\n",
    "doctor_persona = Doctor(\n",
    "    name=\"Dr. Smith\",\n",
    "    gender=\"male\",\n",
    "    age=52,\n",
    "    specialty=\"Family Medicine\"\n",
    ")\n",
    "generator_doctor = PersonaGenerator(doctor_persona)\n",
    "persona_cards = generator_doctor.generate(n=1)\n",
    "persona_cards.to_file(f\"{persona_card_folder}/persona_doctor.json\")\n",
    "\n",
    "# Generate patient persona\n",
    "patient_persona = Patient(\n",
    "    name=\"John Doe\",\n",
    "    gender=\"male\",\n",
    "    age=62\n",
    ")\n",
    "generator_patient = PersonaGenerator(patient_persona)\n",
    "persona_cards = generator_patient.generate(n=1)\n",
    "persona_cards.to_file(f\"{persona_card_folder}/persona_patient.json\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load persona"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load personas\n",
    "persona_doctor = Persona.from_file(\"./personas/persona_doctor.json\")\n",
    "persona_patient = Persona.from_file(\"./personas/persona_patient.json\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%script false --no-raise-error\n",
    "context = \"Generate me a 50 turn medical dialogue between patient and doctor, for a primary care visit\"\n",
    "\n",
    "# Create agents\n",
    "agent1 = PersonaAgent(persona=persona_doctor, name=\"DOCTOR\", dialogue_details=context, response_details=\"make short turn answers when needed\")\n",
    "agent2 = PersonaAgent(persona=persona_patient, name=\"PATIENT\", dialogue_details=context, response_details=\"make short turn answers when needed\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_all = True\n",
    "GENERATE_PERSONA = True\n",
    "FORCE_DIALOG_GENERATION = False\n",
    "\n",
    "os.makedirs(\"./outputs\", exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m\u001b[95m[dialog_id] \u001b[35m1752861530588\u001b[0m\n",
      "\u001b[1m\u001b[95m[model] \u001b[35mclient=<botocore.client.BedrockRuntime object at 0x7fc319ec91c0> model_id='anthropic.claude-3-5-sonnet-20240620-v1:0' region_name='us-east-1' provider='anthropic' supports_tool_choice_values=('auto', 'any', 'tool')\u001b[0m\n",
      "\u001b[1m\u001b[95m[seed] \u001b[35m226296126\u001b[0m\n",
      "\u001b[1m\u001b[35m--- Dialogue Begins ---\u001b[0m\n",
      "\u001b[31m[DOCTOR] \u001b[0mHello there. I'm Dr. Smith. Welcome to my office. What brings you in to see me today?\u001b[0m\n",
      "\u001b[94m[PATIENT] \u001b[37mGood morning, Dr. Smith. I'm John Doe. I've been dealing with a persistent cough and feeling pretty tired for about three weeks now. It's starting to wear me down, and I thought I should get it checked out.\u001b[0m\n",
      "\u001b[31m[DOCTOR] \u001b[0mI'm sorry to hear you've been feeling unwell, Mr. Doe. A persistent cough and fatigue can certainly be troublesome. Let's get some more details. Can you describe your cough? Is it dry or productive?\u001b[0m\n",
      "\u001b[94m[PATIENT] \u001b[37mWell, Dr. Smith, it's mostly a dry cough. It's particularly bothersome at night when I'm trying to sleep. You know, it reminds me of the time I was teaching about the Civil War and how soldiers often suffered from \"camp cough\" due to poor conditions. Of course, I doubt my situation is that dire, but it's certainly annoying.\u001b[0m\n",
      "\u001b[1m\u001b[35m--- Dialogue Ends ---\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "if FORCE_DIALOG_GENERATION:\n",
    "\n",
    "    original_dialog = agent1.talk_with(agent2, max_turns=3)\n",
    "    original_dialog.to_file(\"dialog_demo.json\")\n",
    "\n",
    "else:\n",
    "    original_dialog = Dialog.from_file(\"dialog_demo.json\")\n",
    "\n",
    "original_dialog.print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Audio Generation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can generate three type of audios:\n",
    "- (default) Step 1: Raw utterances passed to a TTS model and concatenated to each others to create an audio file\n",
    "- Step 2: Audio generated from multiple channels create using signal positions\n",
    "- Step 3: Audio generated using room spacialization and multi-channels positions\n",
    "\n",
    "If you want to trigger the \"step 2\" you need to give a Scaper argument to the `audio_pipeline`. While for the \"step 3\" you need also to give a \"Room\" in the `inference` function."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Instanciate voices database"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sdialog.audio.voice_database import DummyVoiceDatabase\n",
    "dummy_voice_database = DummyVoiceDatabase()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "OR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sdialog.audio.voice_database import HuggingfaceVoiceDatabase\n",
    "voices_libritts = HuggingfaceVoiceDatabase(\"sdialog/voices-libritts\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "OR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sdialog.audio.voice_database import HuggingfaceVoiceDatabase\n",
    "jsalt_voices = HuggingfaceVoiceDatabase(\"sdialog/voices-jsalt\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Instanciate TTS model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/yanislabrak/opt/miniconda3/envs/jsalt/lib/python3.9/site-packages/torch/nn/modules/rnn.py:83: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.2 and num_layers=1\n",
      "  warnings.warn(\"dropout option adds dropout after all but last \"\n",
      "/Users/yanislabrak/opt/miniconda3/envs/jsalt/lib/python3.9/site-packages/torch/nn/utils/weight_norm.py:28: UserWarning: torch.nn.utils.weight_norm is deprecated in favor of torch.nn.utils.parametrizations.weight_norm.\n",
      "  warnings.warn(\"torch.nn.utils.weight_norm is deprecated in favor of torch.nn.utils.parametrizations.weight_norm.\")\n"
     ]
    }
   ],
   "source": [
    "from sdialog.audio.tts_engine import KokoroTTS\n",
    "tts_pipeline = KokoroTTS()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup stage: Audio Dialog and Audio Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sdialog.audio.audio_dialog import AudioDialog\n",
    "from sdialog.audio.audio_pipeline import AudioPipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "dialog: AudioDialog = AudioDialog.from_dialog(original_dialog)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 1 : Concatenated utterances"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "audio_pipeline = AudioPipeline(\n",
    "    voice_database=dummy_voice_database,\n",
    "    tts_pipeline=tts_pipeline,\n",
    "    dir_audio=\"./outputs\",\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "OR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%script false --no-raise-error\n",
    "audio_pipeline = AudioPipeline() # Default values are used"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2025-07-25 11:15:14] ERROR:asyncio:Future exception was never retrieved\n",
      "future: <Future finished exception=BrokenPipeError(32, 'Broken pipe')>\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/yanislabrak/opt/miniconda3/envs/jsalt/lib/python3.9/asyncio/unix_events.py\", line 665, in write\n",
      "    n = os.write(self._fileno, data)\n",
      "BrokenPipeError: [Errno 32] Broken pipe\n",
      "[W NNPACK.cpp:64] Could not initialize NNPACK! Reason: Unsupported hardware.\n",
      "[2025-07-25 11:15:51] WARNING:root:The dSCAPER is not set, which make the generation of the timeline impossible\n",
      "[2025-07-25 11:15:51] WARNING:root:The room or the dSCAPER is not set, which make the generation of the room accoustic audio impossible\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "./outputs/dialog_1752861530588/exported_audios/audio_pipeline_step1.wav\n"
     ]
    }
   ],
   "source": [
    "dialog: AudioDialog = audio_pipeline.inference(dialog) # Generate the audio for the dialog\n",
    "print(dialog.audio_step_1_filepath) # Path to the audio of the first stage of the audio pipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 2: dScaper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%script false --no-raise-error\n",
    "!git clone https://github.com/cyrta/dscaper.git"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%script false --no-raise-error\n",
    "%pip install -r ../../../requirements-dscaper.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "import scaper\n",
    "DATA_PATH = \"./dscaper_data\" # Path where the sound events, utterances and timelines database will be saved\n",
    "os.makedirs(DATA_PATH, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "dsc = scaper.Dscaper(dscaper_base_path=DATA_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/yanislabrak/opt/miniconda3/envs/jsalt/lib/python3.9/site-packages/torch/nn/modules/rnn.py:83: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.2 and num_layers=1\n",
      "  warnings.warn(\"dropout option adds dropout after all but last \"\n",
      "/Users/yanislabrak/opt/miniconda3/envs/jsalt/lib/python3.9/site-packages/torch/nn/utils/weight_norm.py:28: UserWarning: torch.nn.utils.weight_norm is deprecated in favor of torch.nn.utils.parametrizations.weight_norm.\n",
      "  warnings.warn(\"torch.nn.utils.weight_norm is deprecated in favor of torch.nn.utils.parametrizations.weight_norm.\")\n"
     ]
    }
   ],
   "source": [
    "audio_pipeline = AudioPipeline(dscaper=dsc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Populating dSCAPER with sdialog/background dataset...:   0%|          | 0/4 [00:00<?, ?it/s][2025-07-25 11:16:47] ERROR:root:Problem storing audio /Users/yanislabrak/.cache/huggingface/hub/datasets--sdialog--background/snapshots/899f03337bf907855fa99ececdadbcabf3705ab6/ac_noise/351790__reiyamanor__small-room-tone-vintage-air-condition-at.wav (the audio can also be already stored)\n",
      "Populating dSCAPER with sdialog/background dataset...:  25%|██▌       | 1/4 [00:01<00:05,  1.72s/it][2025-07-25 11:16:47] ERROR:root:Problem storing audio /Users/yanislabrak/.cache/huggingface/hub/datasets--sdialog--background/snapshots/899f03337bf907855fa99ececdadbcabf3705ab6/ac_noise/546572__tim_verberne__f_st_room_tone_04.wav (the audio can also be already stored)\n",
      "[2025-07-25 11:16:47] ERROR:root:Problem storing audio /Users/yanislabrak/.cache/huggingface/hub/datasets--sdialog--background/snapshots/899f03337bf907855fa99ececdadbcabf3705ab6/fan_noise/210098__yuval__room-big-fan.wav (the audio can also be already stored)\n",
      "Populating dSCAPER with sdialog/background dataset...:  75%|███████▌  | 3/4 [00:01<00:00,  1.91it/s][2025-07-25 11:16:47] ERROR:root:Problem storing audio /Users/yanislabrak/.cache/huggingface/hub/datasets--sdialog--background/snapshots/899f03337bf907855fa99ececdadbcabf3705ab6/fan_noise/674563__klankbeeld__room-tone-fan-801am-220813_0497.wav (the audio can also be already stored)\n",
      "Populating dSCAPER with sdialog/background dataset...: 100%|██████████| 4/4 [00:02<00:00,  1.93it/s]\n",
      "Populating dSCAPER with sdialog/foreground dataset...:   0%|          | 0/8 [00:00<?, ?it/s][2025-07-25 11:16:50] ERROR:root:Problem storing audio /Users/yanislabrak/.cache/huggingface/hub/datasets--sdialog--foreground/snapshots/d3249cd6ec624a5fb525ae5a41e97cc9770b36ef/chair_sitting_down/249570__rivernile7__sitting-down-on-chair.wav (the audio can also be already stored)\n",
      "[2025-07-25 11:16:50] ERROR:root:Problem storing audio /Users/yanislabrak/.cache/huggingface/hub/datasets--sdialog--foreground/snapshots/d3249cd6ec624a5fb525ae5a41e97cc9770b36ef/keyboard_typing/331428__m4taiori__mechanical-keyboard-typing.mp3 (the audio can also be already stored)\n",
      "[2025-07-25 11:16:50] ERROR:root:Problem storing audio /Users/yanislabrak/.cache/huggingface/hub/datasets--sdialog--foreground/snapshots/d3249cd6ec624a5fb525ae5a41e97cc9770b36ef/keyboard_typing/332458__thegreatrazz__keyboard-typing.wav (the audio can also be already stored)\n",
      "[2025-07-25 11:16:51] ERROR:root:Problem storing audio /Users/yanislabrak/.cache/huggingface/hub/datasets--sdialog--foreground/snapshots/d3249cd6ec624a5fb525ae5a41e97cc9770b36ef/keyboard_typing/376960__director1406__keyboard-typing-fast.mp3 (the audio can also be already stored)\n",
      "Populating dSCAPER with sdialog/foreground dataset...:  50%|█████     | 4/8 [00:00<00:00, 24.86it/s][2025-07-25 11:16:51] ERROR:root:Problem storing audio /Users/yanislabrak/.cache/huggingface/hub/datasets--sdialog--foreground/snapshots/d3249cd6ec624a5fb525ae5a41e97cc9770b36ef/keyboard_typing/546166__grcekh__keyboard-typing-9-whitefox-mechanical.mp3 (the audio can also be already stored)\n",
      "[2025-07-25 11:16:51] ERROR:root:Problem storing audio /Users/yanislabrak/.cache/huggingface/hub/datasets--sdialog--foreground/snapshots/d3249cd6ec624a5fb525ae5a41e97cc9770b36ef/keyboard_typing/559892__sorinious_genious__keyboard-fast-typing-no-accents.wav (the audio can also be already stored)\n",
      "[2025-07-25 11:16:51] ERROR:root:Problem storing audio /Users/yanislabrak/.cache/huggingface/hub/datasets--sdialog--foreground/snapshots/d3249cd6ec624a5fb525ae5a41e97cc9770b36ef/keyboard_typing/665075__zrrion__keyboard-typing-sounds-unidentified-technics-keyboard.ogg (the audio can also be already stored)\n",
      "Populating dSCAPER with sdialog/foreground dataset...:  88%|████████▊ | 7/8 [00:00<00:00, 12.88it/s][2025-07-25 11:16:51] ERROR:root:Problem storing audio /Users/yanislabrak/.cache/huggingface/hub/datasets--sdialog--foreground/snapshots/d3249cd6ec624a5fb525ae5a41e97cc9770b36ef/white_noise/37612__soundstack__white-noise-impulse.wav (the audio can also be already stored)\n",
      "Populating dSCAPER with sdialog/foreground dataset...: 100%|██████████| 8/8 [00:00<00:00, 15.85it/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Populate the sound events database\n",
    "audio_pipeline.populate_dscaper([\"sdialog/background\",\"sdialog/foreground\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/yanislabrak/Desktop/HUB/JSALT/sdialog/dscaper/scaper/core.py:1657: ScaperWarning: PATIENT event duration (18.40) is greater that source duration (18.38), changing to 18.38\n",
      "  warnings.warn(\n",
      "/Users/yanislabrak/Desktop/HUB/JSALT/sdialog/dscaper/scaper/core.py:1657: ScaperWarning: DOCTOR event duration (5.60) is greater that source duration (5.58), changing to 5.58\n",
      "  warnings.warn(\n",
      "/Users/yanislabrak/Desktop/HUB/JSALT/sdialog/dscaper/scaper/core.py:1657: ScaperWarning: DOCTOR event duration (12.40) is greater that source duration (12.38), changing to 12.38\n",
      "  warnings.warn(\n",
      "/Users/yanislabrak/Desktop/HUB/JSALT/sdialog/dscaper/scaper/core.py:1657: ScaperWarning: white_noise event duration (0.10) is greater that source duration (0.02), changing to 0.02\n",
      "  warnings.warn(\n",
      "[2025-07-25 11:17:34] INFO:root:Successfully generated dscaper timeline.\n",
      "[2025-07-25 11:17:34] WARNING:root:The room or the dSCAPER is not set, which make the generation of the room accoustic audio impossible\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "./outputs/dialog_1752861530588/exported_audios/audio_pipeline_step1.wav\n",
      "./outputs/dialog_1752861530588/exported_audios/audio_pipeline_step2.wav\n"
     ]
    }
   ],
   "source": [
    "dialog: AudioDialog = audio_pipeline.inference(dialog)\n",
    "print(dialog.audio_step_1_filepath)\n",
    "print(dialog.audio_step_2_filepath)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 3 : Room Accoustics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/yanislabrak/opt/miniconda3/envs/jsalt/lib/python3.9/site-packages/torch/nn/modules/rnn.py:83: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.2 and num_layers=1\n",
      "  warnings.warn(\"dropout option adds dropout after all but last \"\n",
      "/Users/yanislabrak/opt/miniconda3/envs/jsalt/lib/python3.9/site-packages/torch/nn/utils/weight_norm.py:28: UserWarning: torch.nn.utils.weight_norm is deprecated in favor of torch.nn.utils.parametrizations.weight_norm.\n",
      "  warnings.warn(\"torch.nn.utils.weight_norm is deprecated in favor of torch.nn.utils.parametrizations.weight_norm.\")\n"
     ]
    }
   ],
   "source": [
    "audio_pipeline = AudioPipeline(dscaper=dsc) # The audio pipeline doesn't change"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sdialog.audio.room import MicrophonePosition\n",
    "from sdialog.audio.room_generator import RoomGenerator, RoomRole"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5077:  RoomRole.CONSULTATION room_5077, desc: consultation room (dimentions: dim: [4.018706259482024, 2.363944858518838, 3.0], rt60: 0.5) role: RoomRole.CONSULTATION)  \n"
     ]
    }
   ],
   "source": [
    "room = RoomGenerator().generate(RoomRole.CONSULTATION)\n",
    "print(room)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2025-07-25 11:18:36] ERROR:root:Problem storing audio for turn ./outputs/dialog_1752861530588/utterances/0_DOCTOR.wav\n",
      "[2025-07-25 11:18:36] ERROR:root:Problem storing audio for turn ./outputs/dialog_1752861530588/utterances/1_PATIENT.wav\n",
      "[2025-07-25 11:18:36] ERROR:root:Problem storing audio for turn ./outputs/dialog_1752861530588/utterances/2_DOCTOR.wav\n",
      "[2025-07-25 11:18:36] ERROR:root:Problem storing audio for turn ./outputs/dialog_1752861530588/utterances/3_PATIENT.wav\n",
      "/Users/yanislabrak/Desktop/HUB/JSALT/sdialog/dscaper/scaper/core.py:1739: ScaperWarning: ac_noise source time tuple (const, 0.0) could not be satisfied given source duration (30.00) and event duration (47.77), source time tuple changed to (const, 0) but was still not satisfiable, likely due to using 'normal' distribution with bounds too close to the start or end of the audio file\n",
      "  warnings.warn(\n",
      "/Users/yanislabrak/Desktop/HUB/JSALT/sdialog/dscaper/scaper/core.py:1657: ScaperWarning: DOCTOR event duration (12.40) is greater that source duration (12.38), changing to 12.38\n",
      "  warnings.warn(\n",
      "/Users/yanislabrak/Desktop/HUB/JSALT/sdialog/dscaper/scaper/core.py:1657: ScaperWarning: DOCTOR event duration (5.60) is greater that source duration (5.58), changing to 5.58\n",
      "  warnings.warn(\n",
      "/Users/yanislabrak/Desktop/HUB/JSALT/sdialog/dscaper/scaper/core.py:1657: ScaperWarning: PATIENT event duration (18.40) is greater that source duration (18.38), changing to 18.38\n",
      "  warnings.warn(\n",
      "/Users/yanislabrak/Desktop/HUB/JSALT/sdialog/dscaper/scaper/core.py:1657: ScaperWarning: white_noise event duration (0.10) is greater that source duration (0.02), changing to 0.02\n",
      "  warnings.warn(\n",
      "/Users/yanislabrak/Desktop/HUB/JSALT/sdialog/dscaper/scaper/core.py:2286: ScaperWarning: Soundscape audio is clipping!\n",
      "  warnings.warn('Soundscape audio is clipping!',\n",
      "/Users/yanislabrak/opt/miniconda3/envs/jsalt/lib/python3.9/site-packages/soxbindings/effects.py:93: RuntimeWarning: invalid value encountered in cast\n",
      "  input_data = input_data.astype(np.int32)\n",
      "/Users/yanislabrak/Desktop/HUB/JSALT/sdialog/dscaper/scaper/core.py:2286: ScaperWarning: Soundscape audio is clipping!\n",
      "  warnings.warn('Soundscape audio is clipping!',\n",
      "/Users/yanislabrak/opt/miniconda3/envs/jsalt/lib/python3.9/site-packages/soxbindings/effects.py:93: RuntimeWarning: invalid value encountered in cast\n",
      "  input_data = input_data.astype(np.int32)\n",
      "/Users/yanislabrak/Desktop/HUB/JSALT/sdialog/dscaper/scaper/core.py:2286: ScaperWarning: Soundscape audio is clipping!\n",
      "  warnings.warn('Soundscape audio is clipping!',\n",
      "/Users/yanislabrak/opt/miniconda3/envs/jsalt/lib/python3.9/site-packages/soxbindings/effects.py:93: RuntimeWarning: invalid value encountered in cast\n",
      "  input_data = input_data.astype(np.int32)\n",
      "[2025-07-25 11:18:39] INFO:root:Successfully generated dscaper timeline.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Microphone set to position [1.1046765648705061, 0.3545917287778257, 1.2]\n",
      "  Microphone set to position [2.009353129741012, 1.181972429259419, 2.9]\n",
      "✓ Loaded audio file './dscaper_data/timelines/dialog_1752861530588/generate/fd8a0ff0-aa05-4fcf-ad23-9a84014d9450/soundscape_positions/no_type.wav' for 'no_type' with 2106877 samples\n",
      "✓ Loaded audio file './dscaper_data/timelines/dialog_1752861530588/generate/fd8a0ff0-aa05-4fcf-ad23-9a84014d9450/soundscape_positions/doctor-at_desk_sitting.wav' for 'doctor-at_desk_sitting' with 2106877 samples\n",
      "✓ Loaded audio file './dscaper_data/timelines/dialog_1752861530588/generate/fd8a0ff0-aa05-4fcf-ad23-9a84014d9450/soundscape_positions/patient-next_to_desk_sitting.wav' for 'patient-next_to_desk_sitting' with 2106877 samples\n",
      "✓ Loaded audio file './dscaper_data/timelines/dialog_1752861530588/generate/2e539e6c-f23d-4b3f-8cc9-dc26c7f4d0b0/soundscape_positions/no_type.wav' for 'no_type' with 2106877 samples\n",
      "✓ Loaded audio file './dscaper_data/timelines/dialog_1752861530588/generate/2e539e6c-f23d-4b3f-8cc9-dc26c7f4d0b0/soundscape_positions/doctor-at_desk_sitting.wav' for 'doctor-at_desk_sitting' with 2106877 samples\n",
      "✓ Loaded audio file './dscaper_data/timelines/dialog_1752861530588/generate/2e539e6c-f23d-4b3f-8cc9-dc26c7f4d0b0/soundscape_positions/patient-next_to_desk_sitting.wav' for 'patient-next_to_desk_sitting' with 2106877 samples\n",
      "./outputs/dialog_1752861530588/exported_audios/audio_pipeline_step1.wav\n",
      "./outputs/dialog_1752861530588/exported_audios/audio_pipeline_step2.wav\n",
      "./outputs/dialog_1752861530588/exported_audios/audio_pipeline_step3.wav\n"
     ]
    }
   ],
   "source": [
    "dialog: AudioDialog = audio_pipeline.inference(\n",
    "    dialog,\n",
    "    room=room, # Need to provide a room object to trigger the 3rd step of the audio pipeline\n",
    "    # microphone_position=MicrophonePosition.MONITOR # Default is MicrophonePosition.CEILING_CENTERED\n",
    ")\n",
    "print(dialog.audio_step_1_filepath)\n",
    "print(dialog.audio_step_2_filepath)\n",
    "print(dialog.audio_step_3_filepath)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Automatic Position and SNR completion (under construction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sdialog.audio.audio_events_enricher import AudioEventsEnricher\n",
    "enricher = AudioEventsEnricher()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "audio_pipeline = AudioPipeline(enricher=enricher)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for turn in dialog.turns:\n",
    "    print(turn.text)\n",
    "    print(turn.position)\n",
    "    print(turn.snr)\n",
    "    print(\"____________________\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## dialog.to_audio()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Add a demo of the audio generation pipeline from the dialog object"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Audio Evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Utterance level evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sdialog.audio.evaluation import compute_evaluation_utterances, compute_evaluation_audio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Utterances level evaluation\n",
    "metrics_utterances_level = compute_evaluation_utterances(dialog)\n",
    "for key, value in metrics_utterances_level.items():\n",
    "    print(f\"{key}: {value}\")\n",
    "\n",
    "# Audio level evaluation\n",
    "metrics_audio_level = compute_evaluation_audio(dialog)\n",
    "for key, value in metrics_audio_level.items():\n",
    "    print(f\"{key}: {value}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Audio level evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Evaluate the final generated audio"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "jsalt",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.23"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
